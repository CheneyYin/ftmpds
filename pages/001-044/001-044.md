Michel Raynal  

# Fault-Tolerant   Message-Passing   Distributed Systems  

An Algorithmic Approach  

#  

Michel Raynal  IRISA-ISTIC Université de Rennes 1  Institut Universitaire de France  Rennes, France  

Parts of this work are based on the books “Fault-Tolerant Agreement in Synchronous MessagePassing Systems” and “Communication and Agreement Abstractions for Fault-Tolerant Asynchronous Distributed Systems”, author Michel Raynal,  $\copyright$   2010 Morgan & Claypool Publishers ( www. morgan claypool.com ). Used with permission.  

ISBN 978-3-319-94140-0 ISBN 978-3-319-94141-7 (eBook)  https://doi.org/10.1007/978-3-319-94141-7  

Library of Congress Control Number: 2018953101  

$\copyright$   Springer Nature Switzerland AG 2018  

# Preface  

La recherche du temps perdu passait par le Web. [...] La m´emoire ´etait devenue in´epuisable, mais la profondeur du temps [...] avait disparu. On ´etait dans un pr´esent inﬁni. In  Les ann´ees  (2008), Annie Ernaux (1940)  

Sed nos immensum spatiis confecimus aequor, Et iam tempus equum fumentia solvere colla. In  Georgica, Liber II, 541-542 , Publius Virgilius (70 BC–19 BC)  

Je suis arriv´e au jour o\`u je ne me souviens plus quand j’ai cess´e d’ˆetre immortel. In  Livro de Cr´onicas , Ant´onio Lobo Antunes (1942)  

C’est une chose ´etrange \`a la ﬁn que le monde Un jour je m’en irai sans en avoir tout dit. In  Les yeux et la m´emoire (1954), chant II , Louis Aragon (1897–1982)  

Tout garder, c’est tout d´etruire. Jacques Derrida (1930–2004)  

What is distributed computing? Distributed computing was born in the late 1970s when researchers and practitioners started taking into account the intrinsic characteristic of physically distributed systems. The ﬁeld then emerged as a specialized research area distinct from networking, operating systems, and parallel computing.  

Distributed computing  arises when one has to solve a problem in terms of distributed entities (usually called processors, nodes, processes, actors, agents, sensors, peers, etc.) such that each entity has only a partial knowledge of the many parameters involved in the problem that has to be solved. While parallel computing and real-time computing can be characterized, respectively, by the terms efﬁciency  and  on-time computing , distributed computing can be characterized by the term  uncertainty . This uncertainty is created by asynchrony, multiplicity of control ﬂows, absence of shared memory and global time, failure, dynamicity, mobility, etc. Mastering one form or another of uncertainty is pervasive in all distributed computing problems. A main difﬁculty in designing distributed algorithms comes from the fact that no entity cooperating in the achievement of a common goal can have an instantaneous knowledge of the current state of the other entities, it can only know their past local states.  

Although distributed algorithms are often made up of a few lines, their behavior can be difﬁcult to understand and their properties hard to state and prove. Hence, distributed computing is not only a fundamental topic but also a challenging topic where simplicity, elegance, and beauty are ﬁrst-class citizens.  

Why this book? In the book “ Distributed algorithms for message-passing systems ” (Springer, 2013), I addressed distributed computing in failure-free message-passing systems, where the computing entities (processes) have to cooperate in the presence of asynchrony. Differently, in my book “ Concurrent programming: algorithms, principles and foundations ” (Springer, 2013), I addressed distributed computing where the computing entities (processes) communicate through a read/write shared memory

 (e.g., multicore), and the main  adversary  lies in the net effect of asynchrony and process crashes

 (unexpected deﬁnitive stops).  

The present book considers synchronous and asynchronous message-passing systems, where processes can commit crash failures, or Byzantine failures (arbitrary behavior). Its aim is to present in a comprehensive way basic notions, concepts and algorithms in the context of these systems. The main difﬁculty comes from the uncertainty created by the  adversaries  managing the  environment  (mainly asynchrony and failures), which, by its very nature, is not under the control of the system.  

A quick look at the content of the book The book is composed of four parts, the ﬁrst two are on communication abstractions , the other two on  agreement abstractions . Those are the most important abstractions distributed applications rely on in asynchronous and synchronous message-passing systems where processes may crash, or commit Byzantine failures. The book addresses what can be done and what cannot be done in the presence of such adversaries. It consequently presents both impossibility results and distributed algorithms. All impossibility results are proved, and all algorithms are described in a simple algorithmic notation and proved correct.  

•  Parts on communication abstractions. –  Part I is on the reliable broadcast abstraction.  

–  Part II is on the construction of read/write registers.  

•  Parts on agreement. –  Part III is on agreement in synchronous systems. –  Part IV is on agreement in asynchronous systems.  

On the presentation style When known, the names of the authors of a theorem, or of an algorithm, are indicated together with the date of the associated publication. Moreover, each chapter has a biblio graphical section, where a short historical perspective and references related to that chapter are given.  

Each chapter terminates with a few exercises and problems, whose solutions can be found in the article cited at the end of the corresponding exercise/problem.  

From a vocabulary point of view, the following terms are used: an  object  implements an  abstraction , deﬁned by a set of properties, which allows a  problem  to be solved. Moreover, each algorithm is ﬁrst presented intuitively with words, and then proved correct. Understanding an algorithm is a two-step process:  

•  First have a good intuition of its underlying principles, and its possible behaviors. This is necessary, but remains informal. •  Then prove the algorithm is correct in the model it was designed for. The proof consists in a logical reasoning, based on the properties provided by (i) the underlying model, and (ii) the statements (code) of the algorithm. More precisely, each property deﬁning the abstraction the algorithm is assumed to implement must be satisﬁed in all its executions.  

Only when these two steps have been done, can we say that we understand the algorithm.  

Audience This book has been written primarily for people who are not familiar with the topic and the concepts that are presented. These include mainly:  

•  Senior-level undergraduate students and graduate students in informatics or computing engineering, who are interested in the principles and algorithmic foundations of fault-tolerant distributed computing. •  Practitioners and engineers who want to be aware of the state-of-the-art concepts, basic principles, mechanisms, and techniques encountered in fault-tolerant distributed computing.  

Prerequisites for this book include undergraduate courses on algorithms, basic knowledge on operating systems, and notions on concurrency in failure-free distributed computing. One-semester courses, based on this book, are suggested in the section titled “How to Use This Book” in the  Afterword .  

Origin of the book and acknowledgments This book has two complementary origins:  

•  The ﬁrst is a set of lectures for undergraduate and graduate courses on distributed computing I gave at the University of Rennes (France), the Hong Kong Polytechnic University, and, as an invited professor, at several universities all over the world. Hence, I want to thank the numerous students for their questions that, in one way or another, contributed to this book. •  The second is the two monographs I wrote in 2010, on fault-tolerant distributed computing, titled “ Communication and agreement abstractions for fault-tolerant asynchronous distributed  

systems ”, and “ Fault-tolerant agreement in synchronous distributed systems ”. Parts of them appear in this book, after having been revised, corrected, and improved. Hence, I want to thank Morgan & Claypool, and more particularly Diane Cerra, for their permission to reuse parts of this work.  

I also want to thank my colleagues (in no particular order) A. Most´efaoui, D. Imbs, S. Rajsbaum, V. Gramoli, C. Delporte, H. Fauconnier, F. Ta¨ıani, M. Perrin, A. Casta˜neda, M. Larrea, and Z. Bouzid, with whom I collaborated in the recent past years. I also thank the Polytechnic University of Hong Kong (PolyU), and more particularly Professor Jiannong Cao, for hosting me while I was writing parts of this book. My thanks also to Ronan Nugent (Springer) for his support and his help in putting it all together.  

Last but not least (and maybe most importantly), I thank all the researchers whose results are presented in this book. Without their work, this book would not exist. (Finally, since I typeset the entire text myself –  $\mathrm{EX2}_{\epsilon}$   for the text and  xﬁg  for ﬁgures – any typesetting or technical errors that remain are my responsibility.)  

Professor Michel Raynal  

Academia Europaea Institut Universitaire de France Professor IRISA-ISTIC, Universit´e de Rennes 1, France Chair Professor, Hong Kong Polytechnic University  

June–December 2017 Rennes, Saint-Gr´egoire, Douelle, Saint-Philibert, Hong Kong, Vienna (DISC’17), Washington D.C. (PODC’17), Mexico City (UNAM)  

# Contents  

I Introductory Chapter 1  

A Few Deﬁnitions and Two Introductory Examples 3 1.1 A Few Deﬁnitions Related to Distributed Computing . . . . . . . . . . . . . . . . . . . 3 1.2 Example 1: Common Decision Despite Message Losses . . . . . . . . . . . . . . . . . 7 1.2.1 The Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 1.2.2 Trying to Solve the Problem: Attempt 1 . . . . . . . . . . . . . . . . . . . . . 9 1.2.3 Trying to Solve the Problem: Attempt 2 . . . . . . . . . . . . . . . . . . . . . 9 1.2.4 An Impossibility Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 1.2.5 A Coordination Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 1.3 Example 2: Computing a Global Function Despite a Message Adversary . . . . . . . . . . . . . . . 11 1.3.1 The Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 1.3.2 The Notion of a Message Adversary . . . . . . . . . . . . . . . . . . . . . . . 12 1.3.3 The TREE-AD Message Adversary . . . . . . . . . . . . . . . . . . . . . . . 13 1.3.4 From Message Adversary to Process Mobility . . . . . . . . . . . . . . . . . . 15 1.4 Main Distributed Computing Models Used in This Book . . . . . . . . . . . . . . . . . 16 1.5 Distributed Computing Versus Parallel Computing . . . . . . . . . . . . . . . . . . . . 17 1.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 1.7 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 1.8 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19  

# II The Reliable Broadcast Communication Abstraction 21  

2 Reliable Broadcast in the Presence of Process Crash Failures 23  

2.1 Uniform Reliable Broadcast . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.1.1 From Best Effort to Guaranteed Reliability . . . . . . . . . . . . . . . . . . . 23 2.1.2 Uniform Reliable Broadcast (URB-broadcast) . . . . . . . . . . . . . . . . . . 24 2.1.3 Building the URB-broadcast Abstraction in    $C A M P_{n,t}[\varnothing]$   . . . . . . . . . . . . 25 2.2 Adding Quality of Service . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 2.2.1 “First In, First Out” (FIFO) Message Delivery . . . . . . . . . . . . . . . . . . 27 2.2.2 “Causal Order” (CO) Message Delivery . . . . . . . . . . . . . . . . . . . . . 29 2.2.3 From FIFO-broadcast to CO-broadcast . . . . . . . . . . . . . . . . . . . . . 31 2.2.4 From URB-broadcast to CO-broadcast: Capturing Causal Past in a Vector . . . 34 2.2.5 The Total Order Broadcast Abstraction Requires More . . . . . . . . . . . . . 38 2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 2.4 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 2.5 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39  

# 3 Reliable Broadcast in the Presence of Process Crashes and Unreliable Channels 41  

3.1 A System Model with Unreliable Channels . . . . . . . . . . . . . . . . . . . . . . . . 41 3.1.1 Fairness Notions for Channels . . . . . . . . . . . . . . . . . . . . . . . . . . 41 3.1.2 Fair Channel (FC) and Fair Lossy Channel . . . . . . . . . . . . . . . . . . . 42 3.1.3 Reliable Channel in the Presence of Process Crashes . . . . . . . . . . . . . . 43 3.1.4 System Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 3.2 URB-broadcast in    $C A M P_{n,t}[\cdot\mathrm{\tiny~FC}]$   . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 3.2.1 URB-broadcast in    $C A M P_{n,t}[\cdot\cdot\operatorname{FC}$  ,   $t<n/2]$   . . . . . . . . . . . . . . . . . . 45 3.2.2 An Impossibility Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 3.3 Failure Detectors: an Approach to Circumvent Impossibilities . . . . . . . . . . . . . . 47 3.3.1 The Concept of a Failure Detector . . . . . . . . . . . . . . . . . . . . . . . . 47 3.3.2 Formal Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 3.4 URB-broadcast in    $C A M P_{n,t}[\cdot\mathrm{\tiny~FC}]$   Enriched with a Failure Detector . . . . . . . . . . 49 3.4.1 Deﬁnition of the Failure Detector Class    $\Theta$   . . . . . . . . . . . . . . . . . . . . 49 3.4.2 Solving URB-broadcast in    $C A M P_{n,t}[\cdot\operatorname{FC},\ \Theta]$   . . . . . . . . . . . . . . . . . 50 3.4.3 Building a Failure Detector    $\Theta$   in    $C A M P_{n,t}[\cdot\operatorname{FC}$  ,   $t<n/2]$  . . . . . . . . . . 50 3.4.4 The Fundamental Added Value Supplied by a Failure Detector . . . . . . . . . 51 3.5 Quiescent Uniform Reliable Broadcast . . . . . . . . . . . . . . . . . . . . . . . . . . 51 3.5.1 The Quiescence Property . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 3.5.2 Quiescent URB-broadcast Based on a Perfect Failure Detector . . . . . . . . . 52 3.5.3 The Class    $H B$   of Heartbeat Failure Detectors . . . . . . . . . . . . . . . . . . 54 3.5.4 Quiescent URB-broadcast in    $C A M P_{n,t}[\cdot\operatorname{FC},\ \Theta,H B]$   . . . . . . . . . . . . . 56 3.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 3.7 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 3.8 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59  

# 4 Reliable Broadcast in the Presence of Byzantine Processes 61  

4.1 Byzantine Processes and Properties of the Model    $B A M P_{n,t}[t<n/3]$  . . . . . . . . . 61 4.2 The No-Duplicity Broadcast Abstraction . . . . . . . . . . . . . . . . . . . . . . . . . 62 4.2.1 Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62 4.2.2 An Impossibility Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63 4.2.3 A No-Duplicity Broadcast Algorithm . . . . . . . . . . . . . . . . . . . . . . 63 4.3 The Byzantine Reliable Broadcast Abstraction . . . . . . . . . . . . . . . . . . . . . . 65 4.4 An Optimal Byzantine Reliable Broadcast Algorithm . . . . . . . . . . . . . . . . . . 66 4.4.1 A Byzantine Reliable Broadcast Algorithm for    $B A M P_{n,t}|t<n/3|$  . . . . . . 66 4.4.2 Correctness Proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 4.4.3 Beneﬁting from Message Asynchrony . . . . . . . . . . . . . . . . . . . . . . 68 4.5 Time and Message-Efﬁcient Byzantine Reliable Broadcast . . . . . . . . . . . . . . . . 69 4.5.1 A Message-Efﬁcient Byzantine Reliable Broadcast Algorithm . . . . . . . . . 70 4.5.2 Correctness Proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 4.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72 4.7 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 4.8 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73  

# III The Read/Write Register Communication Abstraction 75  

5 The Read/Write Register Abstraction 77  

5.1 The Read/Write Register Abstraction . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 5.1.1 Concurrent Objects and Registers . . . . . . . . . . . . . . . . . . . . . . . . 77  

5.1.2 The Notion of a Regular Register . . . . . . . . . . . . . . . . . . . . . . . . 78 5.1.3 Registers Deﬁned from a Sequential Spec i cation . . . . . . . . . . . . . . . . 79 5.2 A Formal Approach to Atomicity and Sequential Consistency . . . . . . . . . . . . . . 81 5.2.1 Processes, Operations, and Events . . . . . . . . . . . . . . . . . . . . . . . . 81 5.2.2 Histories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82 5.2.3 A Formal Deﬁnition of Atomicity . . . . . . . . . . . . . . . . . . . . . . . . 84 5.2.4 A Formal Deﬁnition of Sequential Consistency . . . . . . . . . . . . . . . . . 84 5.3 Composability of Consistency Conditions . . . . . . . . . . . . . . . . . . . . . . . . . 85 5.3.1 What Is Composability? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 5.3.2 Atomicity Is Composable . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 5.3.3 Sequential Consistency Is Not Composable . . . . . . . . . . . . . . . . . . . 87 5.4 Bounds on the Implementation of Strong Consistency Conditions . . . . . . . . . . . . 88 5.4.1 Upper Bound on    $t$   for Atomicity . . . . . . . . . . . . . . . . . . . . . . . . . 88 5.4.2 Upper Bound on    $t$   for Sequential Consistency . . . . . . . . . . . . . . . . . . 89 5.4.3 Lower Bounds on the Durations of Read and Write Operations . . . . . . . . . 90 5.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93 5.6 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93 5.7 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94  

6 Building Read/Write Registers Despite Asynchrony and Less than Half of Processes Crash   $(t<n/2$  ) 95  

6.1 A Structural View . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95 6.2 Building an SWMR Regular Read/Write Register in    $C A M P_{n,t}[t<n/2]$   . . . . . . . . 96 6.2.1 Problem Spec i cation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96 6.2.2 Implementing an SWMR Regular Register in    $C A M P_{n,t}[t<n/2]$   . . . . . . . 97 6.2.3 Proof of the SWMR Regular Register Construction . . . . . . . . . . . . . . . 99 6.3 From an SWMR Regular Register to an SWMR Atomic Register . . . . . . . . . . . . 100 6.3.1 Why the Previous Algorithm Does Not Ensure Atomicity . . . . . . . . . . . . 100 6.3.2 From Regularity to Atomicity . . . . . . . . . . . . . . . . . . . . . . . . . . 100 6.4 From SWMR Atomic Register to MWMR Atomic Register . . . . . . . . . . . . . . . 101 6.4.1 Replacing Sequence Numbers by Timestamps . . . . . . . . . . . . . . . . . . 101 6.4.2 Construction of an MWMR Atomic Register . . . . . . . . . . . . . . . . . . 102 6.4.3 Proof of the MWMR Atomic Register Construction . . . . . . . . . . . . . . . 102 6.5 Implementing Sequentially Consistent Registers . . . . . . . . . . . . . . . . . . . . . 105 6.5.1 How to Address the Non-com pos ability of Sequential Consistency . . . . . . . 105 6.5.2 Algorithms Based on a Total Order Broadcast Abstraction . . . . . . . . . . . 105 6.5.3 A TO-broadcast-based Algorithm with Local (Fast) Read Operations . . . . . 106 6.5.4 A TO-broadcast-based Algorithm with Local (Fast) Write Operations . . . . . 107 6.5.5 An Algorithm Based on Logical Time . . . . . . . . . . . . . . . . . . . . . . 108 6.5.6 Proof of the Logical Time-based Algorithm . . . . . . . . . . . . . . . . . . . 112 6.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115 6.7 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115 6.8 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116  

7 Circumventing the  $t<n/2$   Read/Write Register Impossibility: the Failure Detector Approach 119  

7.1 The Class    $\Sigma$   of Quorum Failure Detectors . . . . . . . . . . . . . . . . . . . . . . . . 119 7.1.1 Deﬁnition of the Class of Quorum Failure Detectors . . . . . . . . . . . . . . 119 7.1.2 Implementing a Failure Detector    $\Sigma$   When    $t<n/2$   . . . . . . . . . . . . . . . 120 7.1.3 A  $\Sigma$  -based Construction of an SWSR Atomic Register . . . . . . . . . . . . . 121  

7.2  $\Sigma$   Is the Weakest Failure Detector to Build an Atomic Register . . . . . . . . . . . . . 122 7.2.1 What Does “Weakest Failure Detector Class” Mean . . . . . . . . . . . . . . . 122 7.2.2 The Extraction Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122 7.2.3 Correctness of the Extraction Algorithm . . . . . . . . . . . . . . . . . . . . . 124 7.3 Comparing the Failure Detectors Classes  $\Theta$   and    $\Sigma$   . . . . . . . . . . . . . . . . . . . . 125 7.4 Atomic Register Abstraction vs URB-broadcast Abstraction . . . . . . . . . . . . . . . 126 7.4.1 From Atomic Registers to URB-broadcast . . . . . . . . . . . . . . . . . . . . 126 7.4.2 Atomic Registers Are Strictly Stronger than URB-broadcast . . . . . . . . . . 127 7.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128 7.6 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128 7.7 Exercise and Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128  

8 A Broadcast Abstraction Suited to the Family of Read/Write Implementable Objects 131  

8.1 The SCD-broadcast Communication Abstraction . . . . . . . . . . . . . . . . . . . . . 132 8.1.1 Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132 8.1.2 Implementing SCD-broadcast in    $C A M P_{n,t}[t<n/2]$   . . . . . . . . . . . . . . 133 8.1.3 Cost and Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . 135 8.1.4 An SCD-broadcast-based Communication Pattern . . . . . . . . . . . . . . . . 139 8.2 From SCD-broadcast to an MWMR Register . . . . . . . . . . . . . . . . . . . . . . . 139 8.2.1 Building an MWMR Atomic Register in    $C A M P_{n,t}$  [ SCD-broadcast ]  . . . . . . 139 8.2.2 Cost and Proof of Correctness . . . . . . . . . . . . . . . . . . . . . . . . . . 141 8.2.3 From Atomicity to Sequential Consistency . . . . . . . . . . . . . . . . . . . 142 8.2.4 From MWMR Registers to an Atomic Snapshot Object . . . . . . . . . . . . . 143 8.3 From SCD-broadcast to an Atomic Counter . . . . . . . . . . . . . . . . . . . . . . . . 144 8.3.1 Counter Object . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144 8.3.2 Implementation of an Atomic Counter Object . . . . . . . . . . . . . . . . . . 145 8.3.3 Implementation of a Sequentially Consistent Counter Object . . . . . . . . . . 146 8.4 From SCD-broadcast to Lattice Agreement . . . . . . . . . . . . . . . . . . . . . . . . 147 8.4.1 The Lattice Agreement Task . . . . . . . . . . . . . . . . . . . . . . . . . . . 147 8.4.2 Lattice Agreement from SCD-broadcast . . . . . . . . . . . . . . . . . . . . . 148 8.5 From SWMR Atomic Registers to SCD-broadcast . . . . . . . . . . . . . . . . . . . . 148 8.5.1 From Snapshot to SCD-broadcast . . . . . . . . . . . . . . . . . . . . . . . . 148 8.5.2 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150 8.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151 8.7 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152 8.8 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153  

# 9 Atomic Read/Write Registers in the Presence of Byzantine Processes 155  

9.1 Atomic Read/Write Registers in the Presence of Byzantine Processes . . . . . . . . . . 155 9.1.1 Why SWMR (and Not MWMR) Atomic Registers? . . . . . . . . . . . . . . . 155 9.1.2 Reminder on Possible Behaviors of a Byzantine Process . . . . . . . . . . . . 155 9.1.3 SWMR Atomic Registers Despite Byzantine Processes: Deﬁnition . . . . . . . 156 9.2 An Impossibility Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157 9.3 Reminder on Byzantine Reliable Broadcast . . . . . . . . . . . . . . . . . . . . . . . . 159 9.3.1 Spec i cation of Multi-shot Reliable Broadcast . . . . . . . . . . . . . . . . . 159 9.3.2 An Algorithm for Multi-shot Byzantine Reliable Broadcast . . . . . . . . . . . 159 9.4 Construction of SWMR Atomic Registers in    $B A M P_{n,t}[t<n/3]$   . . . . . . . . . . . . 16 1 9.4.1 Description of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . 161 9.4.2 Comparison with the Crash Failure Model . . . . . . . . . . . . . . . . . . . . 163  

9.5 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164 9.5.1 Preliminary Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164 9.5.2 Proof of the Termination Properties . . . . . . . . . . . . . . . . . . . . . . . 164 9.5.3 Proof of the Consistency (Atomicity) Properties . . . . . . . . . . . . . . . . . 165 9.5.4 Piecing Together the Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . 166 9.6 Building Objects on Top of SWMR Byzantine Registers . . . . . . . . . . . . . . . . . 166 9.6.1 One-shot Write-snapshot Object . . . . . . . . . . . . . . . . . . . . . . . . . 166 9.6.2 Correct-only Agreement Object . . . . . . . . . . . . . . . . . . . . . . . . . 167 9.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168 9.8 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169 9.9 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169  

# IV Agreement in Synchronous Systems 171  

10 Consensus and Interactive Consistency  

in Synchronous Systems Prone to Process Crash Failures 173 10.1 Consensus in the Crash Failure Model . . . . . . . . . . . . . . . . . . . . . . . . . . 173 10.1.1 Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173 10.1.2 A Simple (Unfair) Consensus Algorithm . . . . . . . . . . . . . . . . . . . . 174 10.1.3 A Simple (Fair) Consensus Algorithm . . . . . . . . . . . . . . . . . . . . . . 175 10.2 Interactive Consistency (Vector Consensus) . . . . . . . . . . . . . . . . . . . . . . . . 177 10.2.1 Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177 10.2.2 A Simple Example of Use: Build Atomic Rounds . . . . . . . . . . . . . . . . 178 10.2.3 An Interactive Consistency Algorithm . . . . . . . . . . . . . . . . . . . . . . 178 10.2.4 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179 10.2.5 A Convergence Point of View . . . . . . . . . . . . . . . . . . . . . . . . . . 181 10.3 Lower Bound on the Number of Rounds . . . . . . . . . . . . . . . . . . . . . . . . . 181 10.3.1 Preliminary Assumptions and Deﬁnitions . . . . . . . . . . . . . . . . . . . . 182 10.3.2 The  $(t+1)$   Lower Bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182 10.3.3 Proof of the Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183 10.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186 10.5 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186 10.6 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186  

11 Expediting Decision in Synchronous Systems with Process Crash Failures 189  

11.1 Early Deciding and Stopping Interactive Consistency . . . . . . . . . . . . . . . . . . . 189 11.1.1 Early Deciding vs Early Stopping . . . . . . . . . . . . . . . . . . . . . . . . 189 11.1.2 An Early Decision Predicate . . . . . . . . . . . . . . . . . . . . . . . . . . . 190 11.1.3 An Early Deciding and Stopping Algorithm . . . . . . . . . . . . . . . . . . . 191 11.1.4 Correctness Proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192 11.1.5 On Early Decision Predicates . . . . . . . . . . . . . . . . . . . . . . . . . . 194 11.1.6 Early Deciding and Stopping Consensus . . . . . . . . . . . . . . . . . . . . . 195 11.2 An Unbeatable Binary Consensus Algorithm . . . . . . . . . . . . . . . . . . . . . . . 196 11.2.1 A Knowledge-Based Unbeatable Predicate . . . . . . . . . . . . . . . . . . . 196 11.2.2  PREF 0()  with Respect to  DIFF () . . . . . . . . . . . . . . . . . . . . . . . . 197 11.2.3 An Algorithm Based on the Predicate  PREF 0() :  CGM  . . . . . . . . . . . . . 197 11.2.4 On the Un beat ability of the Predicate  PREF 0()  . . . . . . . . . . . . . . . . . 200  

11.3 The Synchronous Condition-based Approach . . . . . . . . . . . . . . . . . . . . . . . 200  

11.3.1 The Condition-based Approach in Synchronous Systems . . . . . . . . . . . . 200 11.3.2 Legality and Maximality of a Condition . . . . . . . . . . . . . . . . . . . . . 201 11.3.3 Hierarchy of Legal Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . 203 11.3.4 Local View of an Input Vector . . . . . . . . . . . . . . . . . . . . . . . . . . 204 11.3.5 A Synchronous Condition-based Consensus Algorithm . . . . . . . . . . . . . 204 11.3.6 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205

 11.4 Using a Global Clock and a Fast Failure Detector . . . . . . . . . . . . . . . . . . . . . 207 11.4.1 Fast Perfect Failure Detectors . . . . . . . . . . . . . . . . . . . . . . . . . . 207 11.4.2 Enriching the Synchronous Model to Beneﬁt from a Fast Failure Detector . . . 208 11.4.3 A Simple Consensus Algorithm Based on a Fast Failure Detector . . . . . . . 208 11.4.4 An Early Deciding and Stopping Algorithm . . . . . . . . . . . . . . . . . . . 209

 11.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212

 11.6 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212

 11.7 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213  

# 12 Consensus Variants: Simultaneous Consensus and    $k$  -Set Agreement 215  

12.1 Simultaneous Consensus: Deﬁnition and Its Difﬁculty . . . . . . . . . . . . . . . . . . 215 12.1.1 Deﬁnition of Simultaneous Consensus . . . . . . . . . . . . . . . . . . . . . . 215 12.1.2 Difﬁculty Early Deciding Before    $(t+1)$   Rounds . . . . . . . . . . . . . . . . 216 12.1.3 Failure Pattern, Failure Discovery, and Waste . . . . . . . . . . . . . . . . . . 216 12.1.4 A Clean Round and the Horizon of a Round . . . . . . . . . . . . . . . . . . . 217

 12.2 An Optimal Simultaneous Consensus Algorithm . . . . . . . . . . . . . . . . . . . . . 218 12.2.1 An Optimal Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218 12.2.2 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220

 12.3 The  $k$  -Set Agreement Abstraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222 12.3.1 Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222 12.3.2 A Simple Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222

 12.4 Early Deciding and Stopping    $k$  -Set Agreement . . . . . . . . . . . . . . . . . . . . . . 224 12.4.1 An Early Deciding and Stopping Algorithm . . . . . . . . . . . . . . . . . . . 224 12.4.2 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224

 12.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227

 12.6 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227

 12.7 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228  

# 13 Non-blocking Atomic Commitment  

in Synchronous Systems with Process Crash Failures 231  

13.1 The Non-blocking Atomic Commitment (NBAC) Abstraction . . . . . . . . . . . . . . 231 13.1.1 Deﬁnition of Non-blocking Atomic Commitment . . . . . . . . . . . . . . . . 231 13.1.2 A Simple Non-blocking Atomic Commitment Algorithm . . . . . . . . . . . . 232

 13.2 Fast Commit and Fast Abort . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233 13.2.1 Looking for Efﬁcient Algorithms . . . . . . . . . . . . . . . . . . . . . . . . 233 13.2.2 An Impossibility Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233

 13.3 Weak Fast Commit and Weak Fast Abort . . . . . . . . . . . . . . . . . . . . . . . . . 236

 13.4 Fast Commit and Weak Fast Abort Are Compatible . . . . . . . . . . . . . . . . . . . 236 13.4.1 A Fast Commit and Weak Fast Abort Algorithm . . . . . . . . . . . . . . . . 236 13.4.2 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238

 13.5 Other Non-blocking Atomic Commitment Algorithms . . . . . . . . . . . . . . . . . . 241 13.5.1 Fast Abort and Weak Fast Commit . . . . . . . . . . . . . . . . . . . . . . . . 241 13.5.2 The Case  $t\leq2$   (System Model    ${C S M P}_{n,t}[1\leq t<3\leq n]$  ) . . . . . . . . . . . 242

 13.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242 13.7 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243 13.8 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244  

# 14 Consensus in Synchronous Systems Prone to Byzantine Process Failures 245  

14.1 Agreement Despite Byzantine Processes . . . . . . . . . . . . . . . . . . . . . . . . . 246 14.1.1 On the Agreement and Validity Properties . . . . . . . . . . . . . . . . . . . . 246 14.1.2 A Consensus Deﬁnition for the Byzantine Failure Model . . . . . . . . . . . . 246 14.1.3 An Interactive Consistency Deﬁnition for the Byzantine Failure Model . . . . 247 14.1.4 The Byzantine General Agreement Abstraction . . . . . . . . . . . . . . . . . 247 14.2 Interactive Consistency for Four Processes Despite One Byzantine Process . . . . . . . 247 14.2.1 An Algorithm for  $n=4$   and    $t=1$   . . . . . . . . . . . . . . . . . . . . . . . . 247 14.2.2 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248 14.3 An Upper Bound on the Number of Byzantine Processes . . . . . . . . . . . . . . . . . 249 14.4 A Byzantine Consensus Algorithm for    $B S M P_{n,t}[t<n/3]$   . . . . . . . . . . . . . . . . 251 14.4.1 Base Data Structure: a Tree . . . . . . . . . . . . . . . . . . . . . . . . . . . 252 14.4.2 EIG Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253 14.4.3 Example of an Execution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254 14.4.4 Proof of the EIG Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . 255 14.5 A Simple Consensus Algorithm with Constant Message Size . . . . . . . . . . . . . . 257 14.5.1 Features of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257 14.5.2 Presentation of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 257 14.5.3 Proof and Properties of the Algorithm . . . . . . . . . . . . . . . . . . . . . . 258 14.6 From Binary to Multivalued Byzantine Consensus . . . . . . . . . . . . . . . . . . . . 259 14.6.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259 14.6.2 A Reduction Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260 14.6.3 Proof of the Multivalued to Binary Reduction . . . . . . . . . . . . . . . . . . 261 14.6.4 An Interesting Property of the Construction . . . . . . . . . . . . . . . . . . . 263 14.7 Enriching the Synchronous Model with Message Authentication . . . . . . . . . . . . . 263 14.7.1 Synchronous Model with Signed Messages . . . . . . . . . . . . . . . . . . . 263 14.7.2 The Gain Obtained from Signatures . . . . . . . . . . . . . . . . . . . . . . . 264 14.7.3 A Synchronous Signature-Based Consensus Algorithm . . . . . . . . . . . . . 264 14.7.4 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265 14.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266 14.9 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266 14.10 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267  

V Agreement in Asynchronous Systems 269  

15 Implementable Agreement Abstractions Despite Asynchrony and a Minority of Process Crashes 271  

15.1 The Renaming Agreement Abstraction . . . . . . . . . . . . . . . . . . . . . . . . . . 271 15.1.1 Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271 15.1.2 A Fundamental Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272 15.1.3 The Stacking Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273 15.1.4 A Snapshot-based Implementation of Renaming . . . . . . . . . . . . . . . . 274 15.1.5 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275 15.2 The Approximate Agreement Abstraction . . . . . . . . . . . . . . . . . . . . . . . . . 276 15.2.1 Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276 15.2.2 A Read/Write-based Implementation of Approximate Agreement . . . . . . . 277  

15.2.3 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277

 15.3 The Safe Agreement Abstraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279 15.3.1 Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279 15.3.2 A Direct Implementation of Safe Agreement in    $C A M P_{n,t}|t<n/2|$   . . . . . . 280 15.3.3 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281

 15.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283

 15.5 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284

 15.6 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284  

# 16 Consensus: Power and Implement ability Limit in Crash-Prone Asynchronous Systems 287  

16.1 The Total Order Broadcast Communication Abstraction . . . . . . . . . . . . . . . . . 287 16.1.1 Total Order Broadcast: Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . 287 16.1.2 A Map of Communication Abstractions . . . . . . . . . . . . . . . . . . . . . 288

 16.2 From Consensus to TO-broadcast . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289 16.2.1 Structure of the Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . 289 16.2.2 Description of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . 289 16.2.3 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291

 16.3 Consensus and TO-broadcast Are Equivalent . . . . . . . . . . . . . . . . . . . . . . . 292

 16.4 The State Machine Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293 16.4.1 State Machine Replication . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293 16.4.2 Sequentially-Deﬁned Abstractions (Objects) . . . . . . . . . . . . . . . . . . 294

 16.5 A Simple Consensus-based Universal Construction . . . . . . . . . . . . . . . . . . . . 295

 16.6 Agreement vs Mutual Exclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296

 16.7 Ledger Object . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297 16.7.1 Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297 16.7.2 Implementation of a Ledger in    $C A M P_{n,t}$  [ TO-broadcast ]  . . . . . . . . . . . . 299

 16.8 Consensus Impossibility in the Presence of Crashes and Asynchrony . . . . . . . . . . 300 16.8.1 The Intuition That Underlies the Impossibility . . . . . . . . . . . . . . . . . . 300 16.8.2 Reﬁning the Deﬁnition of    $C A M P_{n,t}$  [ ∅ ]  . . . . . . . . . . . . . . . . . . . . . 301 16.8.3 Notion of Valence of a Global State . . . . . . . . . . . . . . . . . . . . . . . 303 16.8.4 Consensus Is Impossible in    $C A M P_{n,1}[\varnothing]$   . . . . . . . . . . . . . . . . . . . . 304

 16.9 The Frontier Between Read/Write Registers and Consensus . . . . . . . . . . . . . . . 309 16.9.1 The Main Question . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309 16.9.2 The Notion of Consensus Number in Read/Write Systems . . . . . . . . . . . 310 16.9.3 An Illustration of Herlihy’s Hierarchy . . . . . . . . . . . . . . . . . . . . . . 310 16.9.4 The Consensus Number of a Ledger . . . . . . . . . . . . . . . . . . . . . . . 313

 16.10 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313

 16.11 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314

 16.12 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315  

# 17 Implementing Consensus in Enriched Crash-Prone Asynchronous Systems 317  

17.1 Enriching an Asynchronous System to Implement Consensus . . . . . . . . . . . . . . 317

 17.2 A Message Scheduling Assumption . . . . . . . . . . . . . . . . . . . . . . . . . . . . 318 17.2.1 Message Scheduling (MS) Assumption . . . . . . . . . . . . . . . . . . . . . 318 17.2.2 A Binary Consensus Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . 318 17.2.3 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319 17.2.4 Additional Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321

 17.3 Enriching    $C A M P_{n,t}[\varnothing]$   with a Perpetual Failure Detector . . . . . . . . . . . . . . . . 321 17.3.1 Enriching    $C A M P_{n,t}[\varnothing]$   with a Perfect Failure Detector . . . . . . . . . . . . . 321 17.4 Enriching    $C A M P_{n,t}[t<n/2]$   with an Eventual Leader . . . . . . . . . . . . . . . . . 323  

17.4.1 The Weakest Failure Detector to Implement Consensus . . . . . . . . . . . . . 323 17.4.2 Implementing Consensus in    $C A M P_{n,t}[t<n/2,\;\Omega]$  . . . . . . . . . . . . . . 324 17.4.3 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327 17.4.4 Consensus Versus Eventual Leader Failure Detector . . . . . . . . . . . . . . 329 17.4.5 Notions of Indulgence and Zero-degradation . . . . . . . . . . . . . . . . . . 329 17.4.6 Saving Broadcast Instances . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329 17.5 Enriching    $C A M P_{n,t}[t<n/2]$   with Random iz ation . . . . . . . . . . . . . . . . . . . 330 17.5.1 Asynchronous Randomized Models . . . . . . . . . . . . . . . . . . . . . . . 330 17.5.2 Randomized Consensus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331 17.5.3 Randomized Binary Consensus in    $C A M P_{n,t}|t<n/2,\mathrm{LC}|$   . . . . . . . . . . . 331 17.5.4 Randomized Binary Consensus in    $C A M P_{n,t}|t<n/2,\mathrm{CC}|$   . . . . . . . . . . . 334 17.6 Enriching    $C A M P_{n,t}[t<n/2]$   with a Hybrid Approach . . . . . . . . . . . . . . . . . 337 17.6.1 The Hybrid Approach: Failure Detector and Random iz ation . . . . . . . . . . 337 17.6.2 A Hybrid Binary Consensus Algorithm . . . . . . . . . . . . . . . . . . . . . 338 17.7 A Paxos-inspired Consensus Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 339 17.7.1 The Alpha Communication Abstraction . . . . . . . . . . . . . . . . . . . . . 340 17.7.2 Consensus Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 340 17.7.3 An Implementation of Alpha in    $C A M P_{n,t}[t<n/2]$  . . . . . . . . . . . . . . 341 17.8 From Binary to Multivalued Consensus . . . . . . . . . . . . . . . . . . . . . . . . . . 344 17.8.1 A Reduction Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344 17.8.2 Proof of the Reduction Algorithm . . . . . . . . . . . . . . . . . . . . . . . . 345 17.9 Consensus in One Communication Step . . . . . . . . . . . . . . . . . . . . . . . . . . 346 17.9.1 Aim and Model Assumption on  t . . . . . . . . . . . . . . . . . . . . . . . . 346 17.9.2 A One Communication Step Algorithm . . . . . . . . . . . . . . . . . . . . . 346 17.9.3 Proof of the Early Deciding Algorithm . . . . . . . . . . . . . . . . . . . . . 347 17.10 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 348 17.11 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349 17.12 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350  

18 Implementing Oracles in Asynchronous Systems with Process Crash Failures 353  

18.1 The Two Facets of Failure Detectors . . . . . . . . . . . . . . . . . . . . . . . . . . . 353 18.1.1 The Programming Point of View: Modular Building Block . . . . . . . . . . . 354 18.1.2 The Computability Point of View: Abstraction Ranking . . . . . . . . . . . . 354 18.2    $\Omega$   in    $C A M P_{n,t}[\varnothing]$  : a Direct Impossibility Proof . . . . . . . . . . . . . . . . . . . . . . 355 18.3 Constructing a Perfect Failure Detector (Class    $P$  ) . . . . . . . . . . . . . . . . . . . . 356 18.3.1 Reminder: Deﬁnition of the Class  $P$   of Perfect Failure Detectors . . . . . . . . 356 18.3.2 Use of an Underlying Synchronous System . . . . . . . . . . . . . . . . . . . 357 18.3.3 Applications Generating a Fair Communication Pattern . . . . . . . . . . . . . 358 18.3.4 The Theta Assumption . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359 18.4 Constructing an Eventually Perfect Failure Detector (Class    $\mathrm{\diamond}P$  ) . . . . . . . . . . . . . 361 18.4.1 Reminder: Deﬁnition of an Eventually Perfect Failure Detector . . . . . . . . 361 18.4.2 From Perpetual to Eventual Properties . . . . . . . . . . . . . . . . . . . . . . 361 18.4.3 Eventually Synchronous Systems . . . . . . . . . . . . . . . . . . . . . . . . 361 18.5 On the Efﬁcient Monitoring of a Process by Another Process . . . . . . . . . . . . . . 363 18.5.1 Motivation and System Model . . . . . . . . . . . . . . . . . . . . . . . . . . 363 18.5.2 A Monitoring Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 364 18.6 An Adaptive Monitoring-based Algorithm Building    ${\bigcirc}P$   . . . . . . . . . . . . . . . . . 366 18.6.1 Motivation and Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366  

18.6.2 A Monitoring-Based Adaptive Algorithm for the Failure Detector Class    ${\bigcirc}P$   . . 366 18.6.3 Proof the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 368

 18.7 From the    $t$  -Source Assumption to an  $\Omega$   Eventual Leader . . . . . . . . . . . . . . . . . 369 18.7.1 The  ${\diamond}t$  -Source Assumption and the Model    $C A M P_{n,t}[\diamondsuit t$  -SOURCE ] . . . . . 369 18.7.2 Electing an Eventual Leader in    $C A M P_{n,t}[\diamondsuit t$  -SOURCE ]  . . . . . . . . . . . . 370 18.7.3 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 371

 18.8 Electing an Eventual Leader in    $C A M P_{n,t}[\diamondsuit t$  -MS PAT ]  . . . . . . . . . . . . . . . . . 372 18.8.1 A Query/Response Pattern . . . . . . . . . . . . . . . . . . . . . . . . . . . . 372 18.8.2 Electing an Eventual Leader in    $C A M P_{n,t}[\diamondsuit t$  -MS PAT ] . . . . . . . . . . . . 374 18.8.3 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 375

 18.9 Building    $\Omega$   in a Hybrid Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 376

 18.10 Construction of a Biased Common Coin from Local Coins . . . . . . . . . . . . . . . . 377 18.10.1 Deﬁnition of a Biased Common Coin . . . . . . . . . . . . . . . . . . . . . . 377 18.10.2 The CORE Communication Abstraction . . . . . . . . . . . . . . . . . . . . . 377 18.10.3 Construction of a Common Coin with a Constant Bias . . . . . . . . . . . . . 380 18.10.4 On the Use of a Biased Common Coin . . . . . . . . . . . . . . . . . . . . . . 381

 18.11 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 381

 18.12 Bibliographic notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382

 18.13 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383  

# 19 Implementing Consensus in Enriched Byzantine Asynchronous Systems 385  

19.1 Deﬁnition Reminder and Two Observations . . . . . . . . . . . . . . . . . . . . . . . . 385 19.1.1 Deﬁnition of Byzantine Consensus (Reminder) . . . . . . . . . . . . . . . . . 385 19.1.2 Why Not to Use an Eventual Leader . . . . . . . . . . . . . . . . . . . . . . . 386 19.1.3 On the Weakest Synchrony Assumption for Byzantine Consensus . . . . . . . 386

 19.2 Binary Byzantine Consensus from a Message Scheduling Assumption . . . . . . . . . 387 19.2.1 A Message Scheduling Assumption . . . . . . . . . . . . . . . . . . . . . . . 387 19.2.2 A Binary Byzantine Consensus Algorithm . . . . . . . . . . . . . . . . . . . . 387 19.2.3 Proof of the Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 388 19.2.4 Additional Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 389

 19.3 An Optimal Randomized Binary Byzantine Consensus Algorithm . . . . . . . . . . . . 389 19.3.1 The Binary-Value Broadcast Abstraction . . . . . . . . . . . . . . . . . . . . 389 19.3.2 A Binary Randomized Consensus Algorithm . . . . . . . . . . . . . . . . . . 391 19.3.3 Proof of the BV-Based Binary Byzantine Consensus Algorithm . . . . . . . . 393 19.3.4 From Decision to Decision and Termination . . . . . . . . . . . . . . . . . . . 395

 19.4 From Binary to Multivalued Byzantine Consensus . . . . . . . . . . . . . . . . . . . . 396 19.4.1 A Reduction Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 396 19.4.2 Proof of the Reduction Algorithm . . . . . . . . . . . . . . . . . . . . . . . . 398

 19.5 From Binary to No-intrusion Multivalued Byzantine Consensus . . . . . . . . . . . . . 399 19.5.1 The Validated Byzantine Broadcast Abstraction . . . . . . . . . . . . . . . . . 399 19.5.2 An Algorithm Implementing VBB-broadcast . . . . . . . . . . . . . . . . . . 399 19.5.3 Proof of the VBB-broadcast Algorithm . . . . . . . . . . . . . . . . . . . . . 401 19.5.4 A VBB-Based Multivalued to Binary Byzantine Consensus Reduction . . . . . 402 19.5.5 Proof of the VBB-Based Reduction Algorithm . . . . . . . . . . . . . . . . . 403

 19.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 404

 19.7 Appendix: Proof-of-Work (PoW) Seen as Eventual Byzantine Agreement . . . . . . . . . . . . . . 405

 19.8 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 406

 19.9 Exercises and Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 407 20 Quorum, Signatures, and Overlays 411  

20.1 Quorum Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 411 20.1.1 Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 411 20.1.2 Examples of Use of a Quorum System . . . . . . . . . . . . . . . . . . . . . . 412 20.1.3 A Few Classical Quorums . . . . . . . . . . . . . . . . . . . . . . . . . . . . 413 20.1.4 Quorum Composition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 414 20.2 Digital Signatures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 415 20.2.1 Cipher, Keys, and Signatures . . . . . . . . . . . . . . . . . . . . . . . . . . . 415 20.2.2 How to Build a Secret Key: Difﬁe-Hellman’s Algorithm . . . . . . . . . . . . 416 20.2.3 How to Build a Public Key: Rivest-Shamir-Adleman’s (RSA) Algorithm . . . 417 20.2.4 How to Share a Secret: Shamir’s Algorithm . . . . . . . . . . . . . . . . . . . 417 20.3 Overlay Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 418 20.3.1 On Regular Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 418 20.3.2 Hypercube . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 419 20.3.3 de Bruijn Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 420 20.3.4 Kautz Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 421 20.3.5 Undirected de Bruijn and Kautz Graphs . . . . . . . . . . . . . . . . . . . . . 422 20.4 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 423  

Afterword 425  

Bibliography 431  

453  

# Notation  

![](images/2d81b42cf60106c638477ae137aaf62bbc894f90647c0e9db98ec8be4d9e5ba4.jpg)  

The notation  broadcast    $\mathrm{YPE}(m)$  , where  TYPE  is a message type and  $m$   a message content, is used as a shortcut for “ for each    $j\in\{1,\cdot\cdot\cdot\ ,n\}$   do  send  $\mathrm{YPE}(m)$   to  $p_{j}$   end for ”. Hence, if it is not faulty during its execution,  $p_{i}$   sends the message    $\mathrm{YPE}(m)$   to each process, including itself. Otherwise there is no guarantee on the reception of  $\mathrm{YPE}(m)$  .  

(In Chap. 1 only,    $j\in\{1,\cdot\cdot\cdot\ ,n\}$   is replaced by    $j\in n e i g h b o r s_{i}$  .)  

# Acronyms (1)  

![](images/3a0ae5729e542d67eb034430d3c2caf4c44fe95e1c2da4dd28d40102350e55b8.jpg)  

# Acronyms (2)  

![](images/71333f2ab2061b3aec6c03fac246efa613ae5f44ef8f16376aadf36b2c98b4ba.jpg)  

# Figures   and   Algorithms  

1.1 Basic structure of distributed computing . . . . . . . . . . . . . . . . . . . . . . . . 4

 1.2 Three graph types of particular interest . . . . . . . . . . . . . . . . . . . . . . . . 5

 1.3 Synchronous execution (left) vs. asynchronous execution (right) . . . . . . . . . . . 5

 1.4 Algorithm structure of a common decision-making process . . . . . . . . . . . . . . 8

 1.5 A simple distributed computing framework . . . . . . . . . . . . . . . . . . . . . . 12

 1.6 Examples of graphs produced by a message adversary . . . . . . . . . . . . . . . . 13

 1.7 Distributed computation in    $S M P_{n}$  [ TREE-AD ]  (code for  $p_{i}$  ) . . . . . . . . . . . . . 14

 1.8 The property limiting the power of a TREE-AD message adversary . . . . . . . . . 14

 1.9 Process mobility can be captured by a message adversary in synchronous systems . . 16

 1.10 Sequential or parallel computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

 2.1 An example of the uniform reliable broadcast delivery guarantees . . . . . . . . . . 25

 2.2 URB-broadcast: architectural view . . . . . . . . . . . . . . . . . . . . . . . . . . 26

 2.3 Uniform reliable broadcast in    $C A M P_{n,t}[\varnothing]$   (code for  $p_{i}$  ) . . . . . . . . . . . . . . . 26

 2.4 From URB to FIFO-URB and CO-URB in    $C A M P_{n,t}[\varnothing]$   . . . . . . . . . . . . . . . 27

 2.5 An example of FIFO-URB message delivery . . . . . . . . . . . . . . . . . . . . . 28

 2.6 FIFO-URB uniform reliable broadcast: architecture view . . . . . . . . . . . . . . . 28

 2.7 FIFO-URB message delivery in  $\mathcal{A}S_{n,t}[\varnothing]$   (code for  $p_{i}$  ) . . . . . . . . . . . . . . . . 29

 2.8 An example of CO message delivery . . . . . . . . . . . . . . . . . . . . . . . . . . 30

 2.9 A simple URB-based CO-broadcast construction in    $C A M P_{n,t}[\varnothing]$   (code for    $p_{i}$  ) . . . 31

 2.10 From FIFO-URB to CO-URB message delivery in    $\mathcal{A}S_{n,t}[\varnothing]$   (code for    $p_{i}$  ) . . . . . . 32

 2.11 How the sequence of messages  im  causal past i  is built . . . . . . . . . . . . . . . 32

 2.12 From URB to CO message delivery in    $\mathcal{A}S_{n,t}[\varnothing]$   (code for  $p_{i}$  ) . . . . . . . . . . . . . 35

 2.13 How vectors are used to construct the CO-broadcast abstraction . . . . . . . . . . . 36

 2.14 Proof of the CO-delivery property (second construction) . . . . . . . . . . . . . . . 37

 2.15 Total order message delivery requires cooperation . . . . . . . . . . . . . . . . . . 38

 2.16 Broadcast of lifetime-constrained messages . . . . . . . . . . . . . . . . . . . . . . 40

 3.1 Uniform reliable broadcast in    $C A M P_{n,t}[-$   FC ,   $t<n/2]$   (code for  $p_{i}$  ) . . . . . . . . 45

 3.2 Building  $\Theta$   in    $C A M P_{n,t}[\cdot$  - FC ,   $t<n/2]$   (code for    $p_{i}$  ) . . . . . . . . . . . . . . . . 50

 3.3 Quiescent uniform reliable broadcast in    $C A M P_{n,t}[\$  - FC ,    $\Theta,P]$   (code for  $p_{i}$  ) . . . . 53

 3.4 Quiescent uniform reliable broadcast in    $C A M P_{n,t}[\tau$   FC ,    $\Theta,H B]$   (code for    $p_{i}$  ) . . . 56

 3.5 An example of a network with fair paths . . . . . . . . . . . . . . . . . . . . . . . . 60

 4.1 Implementing ND-broadcast in    $B A M P_{n,t}[t<n/3]$  . . . . . . . . . . . . . . . . . 64

 4.2 An example of ND-broadcast with a Byzantine sender . . . . . . . . . . . . . . . . 65

 4.3 Implementing BRB-broadcast in    $B A M P_{n,t}[t<n/3]$   . . . . . . . . . . . . . . . . . 67

 4.4 Beneﬁting from message asynchrony . . . . . . . . . . . . . . . . . . . . . . . . . 69

 4.5 Exploiting message asynchrony . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69

 4.6 Communication-efﬁcient Byzantine BRB-broadcast in    $B A M P_{n,t}[t<n/5]$   . . . . . 70 5.1 Possible behaviors of a regular register . . . . . . . . . . . . . . . . . . . . . . . . 78

 5.2 A regular register has no sequential speciﬁcation . . . . . . . . . . . . . . . . . . . 79

 5.3 Behavior of an atomic register . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80

 5.4 Behavior of a sequentially consistent register . . . . . . . . . . . . . . . . . . . . . 81

 5.5 Example of a history . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82

 5.6 Partial order on the operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83

 5.7 Developing  ${\mathsf{o p}}1\to_{H}{\mathsf{o p}}2\to_{X}{\mathsf{o p}}3\to_{H}{\mathsf{o p}}4$  . . . . . . . . . . . . . . . . . . . . . 86

 5.8 The execution of the register  $R$   is sequentially consistent . . . . . . . . . . . . . . . 87

 5.9 The execution of the register  $R^{\prime}$    is sequentially consistent . . . . . . . . . . . . . . 87  

 5.10 An execution involving the registers    $R$   and  $R^{\prime}$  . . . . . . . . . . . . . . . . . . . . . 87

 5.11 There is no atomic register algorithm in    $C A M P_{n,t}[\varnothing]$   . . . . . . . . . . . . . . . . . 88

 5.12 There is no algorithm for two sequentially consistent registers in    $C A M P_{n,t}[t\geq n/2]$   89

 5.13 Tradeoff  duration ( read ) +  duration ( write )  ≥ δ  . . . . . . . . . . . . . . . . . . . 91

 5.14 duration ( write )  $\geq u/2$  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92

 6.1 Building a read/write memory on top of    $C A M P_{n,t}[t\leq n/2]$   . . . . . . . . . . . . . 96

 6.2 An algorithm that constructs an SWMR regular register in    $C A M P_{n,t}[t<n/2]$   . . . 98

 6.3 Regularity is not atomicity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100

 6.4 SWMR register: from regularity to atomicity . . . . . . . . . . . . . . . . . . . . . 101

 6.5 Construction of an atomic MWMR register in    $C A M P_{n,t}[t<n/2]$   (code for any    $p_{i}$  ) 103

 6.6 Fast read algorithm implementing sequential consistency (code for  $p_{i}$  ) . . . . . . . . 106

 6.7 Beneﬁting from TO-broadcast . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107

 6.8 Fast write algorithm implementing sequential consistency (code for  $p_{i}$  ) . . . . . . . 108

 6.9 Fast enqueue algorithm implementing a sequentially consistent queue (code for  $p_{i}$  ) . 108

 6.10 Construction of a sequentially consistent MWMR register in    $C A M P_{n,t}[t\,<\,n/2]$  (code for  $p_{i}$  ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109

 6.11 Message exchange pattern for a write operation . . . . . . . . . . . . . . . . . . . . 110

 6.12 First message exchange pattern for a read operation . . . . . . . . . . . . . . . . . . 111

 6.13 Logical time vs. physical time for write operations . . . . . . . . . . . . . . . . . . 112

 6.14 An execution    ${\widehat{H^{\ell d}}}|X$  |  in which  $r e s p(\mathsf{o p1})<_{H^{\ell d}|X}i n v(\mathsf{r e a d2})$   . . . . . . . . . . . . 113

 7.1 Building a failure detector of the class    $\Sigma$   in    $C A M P_{n,t}[t<n/2]$   . . . . . . . . . . . 120

 7.2 An algorithm for an atomic SWSR register in    $C A M P_{n,t}[\Sigma]$  . . . . . . . . . . . . . 121

 7.3 Extracting    $\Sigma$   from a register    $D$  -based algorithm  $A$  . . . . . . . . . . . . . . . . . . 122

 7.4 Extracting    $\Sigma$   from a failure detector-based register algorithm    $A$   (code for  $p_{i}$  ) . . . . 124

 7.5 From atomic registers to URB-broadcast (code for  $p_{i}$  ) . . . . . . . . . . . . . . . . 127

 7.6 From the failure detector class    $\Sigma$   to the URB abstraction   $(1\leq t<n)$  ) . . . . . . . . 128

 7.7 Two examples of the hybrid communication model . . . . . . . . . . . . . . . . . . 129

 8.1 An implementation of SCD-broadcast in    $C A M P_{n,t}[t<n/2]$   (code for    $p_{i}$  ) . . . . . 134

 8.2 Message pattern introduced in Lemma 16 . . . . . . . . . . . . . . . . . . . . . . . 137

 8.3 SCD-broadcast-based communication pattern (code for  $p_{i}$  ) . . . . . . . . . . . . . . 139

 8.4 Construction of an MWMR atomic register in    $C A M P_{n,t}$  [ SCD-broadcast ]  (code for  $p_{i.}$  ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140

 8.5 Construction of an MWMR sequentially consistent register in    $C A M P_{n,t}$  [ SCD-broadcast ] (code for  $p_{i}$  ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143

 8.6 Example of a run of an MWMR atomic snapshot object . . . . . . . . . . . . . . . 143

 8.7 Construction of an MWMR atomic snapshot object in    $C A M P_{n,t}$  [ SCD-broadcast ]  . . 144

 8.8 Construction of an atomic counter in    $C A M P_{n,t}$  [ SCD-broadcast ]  (code for  $p_{i}$  ) . . . . 145  

8.9 Construction of a sequentially consistent counter in    $C A M P_{n,t}$  [ SCD-broadcast ]  (code for    $p_{i}$  ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147

 8.10 Solving lattice agreement in    $C A M P_{n,t}$  [ SCD-broadcast ]  (code for  $p_{i}$  ) . . . . . . . . 148  

8.11 An implementation of SCD-broadcast on top of snapshot objects (code for  $p_{i}$  ) . . . . 149

 9.1 Execution    $E1$   (impossibility of an SWMR register in    $B A M P_{n,t}[t\geq n/3])$  . . . . . 157

 9.2 Execution    $E2$   (impossibility of an SWMR register in    $B A M P_{n,t}[t\geq n/3])$  . . . . . 158

 9.3 Execution    $E3$   (impossibility of an SWMR register in    $B A M P_{n,t}[t\geq n/3])$  . . . . . 158

 9.4 Reliable broadcast with sequence numbers in  $B A M P_{n,t}[t<n/3]$   (code for  $p_{i}$  ) . . . 160

 9.5 Atomic SWMR Registers in  $B A M P_{n,t}[t<n/3]$   (code for    $p_{i}$  ) . . . . . . . . . . . . 162

 9.6 One-shot write-snapshot in  $B A M P_{n,t}[t<n/3]$   (code for    $p_{i}$  ) . . . . . . . . . . . . . 167

 9.7 Correct-only agreement in    $B A M P_{n,t}[t<n/(w+1)]$  . . . . . . . . . . . . . . . . 168

 10.1 A simple (unfair)  $t$  -resilient consensus algorithm in    $C S M P_{n,t}[\emptyset]$   (code for    $p_{i}$  ) . . . . 175

 10.2 A simple (fair)  $t$  -resilient consensus algorithm in    $C S M P_{n,t}[\emptyset]$   (code for  $p_{i}$  ) . . . . . 176

 10.3 The second case of the agreement property (with    $t=3$   crashes) . . . . . . . . . . . 177

 10.4 A    $t$  -resilient interactive consistency algorithm in    $C S M P_{n,t}[\varnothing]$   (code for    $p_{i}$  ) . . . . . 179

 10.5 Three possible one-round extensions from    $E_{t-1}$   . . . . . . . . . . . . . . . . . . . . 183

 10.6 Extending the  $k$  -round execution    $E_{k}$   . . . . . . . . . . . . . . . . . . . . . . . . . . 184

 10.7 Extending two    $(k+1)$  -round executions . . . . . . . . . . . . . . . . . . . . . . . 185

 10.8 Extending again two    $(k+1)$  -round executions . . . . . . . . . . . . . . . . . . . . 185

 11.1 Early decision predicate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191

 11.2 An early deciding  $t$  -resilient interactive consistency algorithm (code for    $p_{i}$  ) . . . . . 192

 11.3 Early stopping synchronous consensus (code for  $p_{i}$  ,    $t<n$  ) . . . . . . . . . . . . . . 195

 11.4 The early decision predicate  revealed 0  $(i,r)$   in action . . . . . . . . . . . . . . . . . 197

 11.5 Local graphs of  $p_{2},p_{3}$  , and  $p_{4}$   at the end of round    $r=1$  . . . . . . . . . . . . . . . 198

 11.6 Local graphs of  $p_{3}$   and  $p_{4}$   at the end of round    $r=2$  . . . . . . . . . . . . . . . . . 198

 11.7 CGM  : Early deciding synchronous consensus based on  PREF 0()  (code for  $p_{i}$  ,  $t<n$  )199

 11.8 Hierarchy of classes of conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . 201

 11.9 A condition-based consensus algorithm (code for  $p_{i}$  ) . . . . . . . . . . . . . . . . . 205

 11.10 Synchronous consensus with a fast failure detector (code for  $p_{i}$  ) . . . . . . . . . . . 209

 11.11 Relevant dates for process    $p_{i}$   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210

 11.12 Early deciding synchronous consensus with a fast failure detector (code for  $p_{i}$  ) . . . 211

 11.13 The pattern used in the proof of the CC-agreement property . . . . . . . . . . . . . 211

 12.1 Clean round vs failure-free round . . . . . . . . . . . . . . . . . . . . . . . . . . . 217

 12.2 Existence of a clean round . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218

 12.3 Optimal simultaneous consensus in the system model    $C S M P_{n,t}[\emptyset]$   (code for  $p_{i}$  ) . . . 219

 12.4 Computing the current horizon value . . . . . . . . . . . . . . . . . . . . . . . . . 219

 12.5 A simple  $k$  -set agreement algorithm for the model    $C S M P_{n,t}$  [ ∅ ]  (code for    $p_{i}$  ) . . . . 223

 12.6 Early stopping synchronous    $k$  -set agreement (code for  $p_{i}$  ,  $t<n$  ) . . . . . . . . . . . 224

 12.7 The differential predicate    $\mathsf{P R E F}(i,r)$   for    $k$  -set agreement . . . . . . . . . . . . . . 224

 12.8 A condition-based simultaneous consensus algorithm (code for  $p_{i}$  ) . . . . . . . . . . 228

 12.9 A simple  $k$  -set agreement algorithm for the model    $C S M P_{n,t}[S O]$   (code for    $p_{i}$  ) . . . 229

 13.1 A consensus-based NBAC algorithm in    $C S M P_{n,t}[\varnothing]$   (code for    $p_{i}$  ) . . . . . . . . . . 232  

13.2 Impossibility of having both fast commit and fast abort when    $t\geq3$   (E3) . . . . . . . 234

 13.3 Impossibility of having both fast commit and fast abort when    $t\geq3$   (E4, E5) . . . . 235

 13.4 Fast commit and weak fast abort NBAC in    ${C S M P}_{n,t}[3\leq t<n]$   (code for  $p_{i}$  ) . . . . 237

 13.5 Fast abort and weak fast commit NBAC in    ${C S M P}_{n,t}[3\leq t<n]$   (code for  $p_{i}$  ) . . . . 242 14.1 Interactive consistency for four processes despite one Byzantine process (code for  $p_{i}$  )248

 14.2 Proof of the interactive consistency algorithm in    $B S M P_{n,t}[t=1,n=4]$  . . . . . . 249

 14.3 Communication graph (left) and behavior of the  $t$   Byzantine processes (right) . . . . 251

 14.4 EIG tree for  $n=4$   and    $t=1$   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252

 14.5 Byzantine EIG consensus algorithm for    $B S M P_{n,t}[t<n/3]$  . . . . . . . . . . . . . 253

 14.6 EIG trees of the correct processes at the end of the ﬁrst round . . . . . . . . . . . . 254

 14.7 EIG tree  tree 2  at the end of the second round . . . . . . . . . . . . . . . . . . . . . 255

 14.8 Constant message size Byzantine consensus in    $B S M P_{n,t}[t<n/4]$  . . . . . . . . . . 258

 14.9 From binary to multivalued Byzantine consensus in    $B S M P_{n,t}[t<n/3]$   (code for    $p_{i}$  ) 260

 14.10 Proof of Property  PR 2  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262

 14.11 Deterministic vs non-deterministic scenarios . . . . . . . . . . . . . . . . . . . . . 263

 14.12 A Byzantine signature-based consensus algorithm in    $B S M P_{n,t}$  [ SIG ;    $t~<~n/2]$  (code for  $p_{i}$  ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265

 15.1 Stacking of abstraction layers for distributed renaming in    $C A M P_{n,t}[t<n/2]$   . . . . 273

 15.2 A simple snapshot-based size-adaptive    $(2p-1)$  -renaming algorithm (code for  $p_{i}$  ) . 274

 15.3 A simple snapshot-based approximate algorithm (code for    $p_{i}$  ) . . . . . . . . . . . . 277

 15.4 What is captured by Lemma 62 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278

 15.5 Safe agreement in    $C A M P_{n,t}[t<n/2]$   (code for process    $p_{i}$  ) . . . . . . . . . . . . . 281

 16.1 Adding total order message delivery to various URB abstractions . . . . . . . . . . 288

 16.2 Adding total order message delivery to the URB abstraction . . . . . . . . . . . . . 289

 16.3 Building the TO-broadcast abstraction in    $C A M P_{n,t}[\mathrm{CONS}]$   (code for    $p_{i}$  ) . . . . . . 290

 16.4 Building the consensus abstraction in    $C A M P_{n,t}$  [ TO-broadcast ]  (code for    $p_{i}$  ) . . . . 293

 16.5 A TO-broadcast-based universal construction (code for    $p_{i}$  ) . . . . . . . . . . . . . . 295

 16.6 A state machine does not allow us to retrieve the past . . . . . . . . . . . . . . . . . 298

 16.7 Building the consensus abstraction in    $C A M P_{n,t}$  [ LEDGER ]  (code for  $p_{i}$  ) . . . . . . 298

 16.8 A TO-broadcast-based ledger construction (code for    $p_{i}$  ) . . . . . . . . . . . . . . . 299

 16.9 Synchrony rules out uncertainty . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301

 16.10 To wait or not to wait in presence of asynchrony and failures? . . . . . . . . . . . . 301

 16.11 Bivalent vs univalent global states . . . . . . . . . . . . . . . . . . . . . . . . . . . 304

 16.12 There is a bivalent initial con gu ration . . . . . . . . . . . . . . . . . . . . . . . . 305

 16.13 Illustrating the sets    $S1$   and  $S2$   used in Lemma 70 . . . . . . . . . . . . . . . . . . . 306

 16.14    $\Sigma2$   contains  0 -valent and  1 -valent global states . . . . . . . . . . . . . . . . . . . . 307  

 16.15 Valence contradiction when    $i\neq i^{\prime}$  . . . . . . . . . . . . . . . . . . . . . . . . . . . 307  

 16.16 Valence contradiction when  i  $i=i^{\prime}$  . . . . . . . . . . . . . . . . . . . . . . . . . . . 308

 16.17    $k$  -sliding window register . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311

 16.18 Solving consensus for  $k$   processes from a  $k$  -sliding window (code for  $p_{i}$  ) . . . . . . 311

 16.19 Schedule illustration: case 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312

 16.20 Schedule illustration: case 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312

 16.21 Building the TO-broadcast abstraction in    $C A M P_{n,t}[\cdot$  - FC ,  CONS ]  (code for  $p_{i}$  ) . . . 316

 17.1 Binary consensus in    $C A M P_{n,t}[t<n/2$  , ]  (code for  $p_{i}$  ) . . . . . . . . . . . . . 319

 17.2 A coordinator-based consensus algorithm for    $C A M P_{n,t}[P]$   (code for    $p_{i}$  ) . . . . . . 322

 17.3  $\Omega$   is a consensus computability lower bound . . . . . . . . . . . . . . . . . . . . . . 325

 17.4 An algorithm implementing consensus in    $C A M P_{n,t}[t<n/2,\;\Omega]$   (code for    $p_{i}$  ) . . . 326

 17.5 The second phase for    $\mathcal{A}S_{n,t}[t<n/3,\Omega]$   (code for  $p_{i}$  ) . . . . . . . . . . . . . . . . 330

 17.6 A randomized binary consensus algorithm for    $C A M P_{n,t}[t<n/2,\mathrm{LC}]$   (code for  $p_{i}$  ) 332

 17.7 What is broken by a random oracle . . . . . . . . . . . . . . . . . . . . . . . . . . 333  

17.8 A randomized binary consensus algorithm for    $C A M P_{n,t}[t<n/2,\mathrm{CC}]$   (code for  $p_{i}$  ) 336

 17.9 A hybrid binary consensus algorithm for    $C A M P_{n,t}[t<n/2,\Omega,\mathrm{LC}]$   (code for  $p_{i}$  ) . . 338

 17.10 An Alpha-based consensus algorithm in    $C A M P_{n,t}[t<n/2,\Omega]$   (code for  $p_{i}$  ) . . . . 340

 17.11 An algorithm implementing Alpha in    $C A M P_{n,t}[t<n/2]$  . . . . . . . . . . . . . . 342

 17.12 A reduction of multivalued to binary consensus in    $C A M P_{n,t}[\mathrm{BC}]$   (code for    $p_{i}$  ) . . . 344

 17.13 Consensus in one communication step in    $C A M P_{n,t}[t<n/3,\mathrm{CONS}]$   (code for  $p_{i}$  ) . 347

 17.14 Is this consensus algorithm for    $C A M P_{n,t}[t<n/2,A\Omega]$   correct? (code for  $p_{i}$  ) . . . 351  

18.1 A simple process monitoring algorithm implementing  $P$   (code for  $p_{i}$  ) . . . . . . . . 357

 18.2 Building a perfect failure detector    $P$   from    $\alpha$  -fair communication (code for    $p_{i}$  ) . . . . 358

 18.3 Building a perfect failure detector    $P$   in    $C A M P_{n,t}[\theta]$   (code for  $p_{i}$  ) . . . . . . . . . . 360

 18.4 Example message pattern in the model    $C A M P_{n,t}[\theta]$   with    $\theta=3$   . . . . . . . . . . . 360

 18.5 Building  ${\bigcirc}P$   from eventual    $\diamondsuit\alpha$  -fair communication (code for    $p_{i}$  ) . . . . . . . . . . 362

 18.6 Building  ${\bigcirc}P$   in    $C A M P_{n,t}[\diamondsuit\mathrm{SYNC}]$   (code for    $p_{i}$  ) . . . . . . . . . . . . . . . . . . 362

 18.7 The maximal value of  $t i m e o u t_{i}[j]$   after GST . . . . . . . . . . . . . . . . . . . . . 363

 18.8 Possible issues with timers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 364

 18.9 A simple monitoring algorithm (  ${\it{p}}_{i}$   monitors    $p_{j}$  ) . . . . . . . . . . . . . . . . . . . . 365

 18.10 The three cases for the arrival of  ALIVE  $(j,s n)$  . . . . . . . . . . . . . . . . . . . . 365

 18.11 An adaptive algorithm that builds  $\mathrm{\diamondsuit}P$   in    $C A M P_{n,t}[\diamondsuit\mathrm{SYNC}]$   (code for    $p_{i}$  ) . . . . . 367

 18.12 Building  $\Omega$   in    $C A M P_{n,t}[\diamondsuit t$  -SOURCE ]  (code for  $p_{i}$  ) . . . . . . . . . . . . . . . . . 371

 18.13 Winning vs losing responses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373

 18.14 An example illustrating the assumption    ${\diamond}t$  -MS PAT . . . . . . . . . . . . . . . . . 373

 18.15 Building  $\Omega$   in    $C A M P_{n,t}[\diamondsuit t\mathrm{-MS\_PAT}]$   (code for  $p_{i.}$  ) . . . . . . . . . . . . . . . . . 374

 18.16 Algorithm implementing CORE-broadcast in    $C A M P_{n,t}[t<n/2]$   (code for  $p_{i}$  ) . . . 378

 18.17 Deﬁnition of    $W[i,j]=1$   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 379

 18.18 Common coin with bias  $\rho\ge1/4$   in    $C A M P_{n,t}[t<n/2,\mathrm{LC,FM}]$   (code for  $p_{i}$  ) . . . . 380

 18.19 Does it build a biased common coin in    $C A M P_{n,t}[t<n/3,\mathrm{LC}]$   (code for    $p_{i}$  )? . . . . 383  

19.1 Binary consensus in    $B A M P_{n,t}[t<n/3$  , ]  (code for    $p_{i}$  ) . . . . . . . . . . . . . 387

 19.2 An algorithm implementing BV-broadcast in    $B A M P_{n,t}[t<n/3]$   (code for    $p_{i}$  ) . . . 390

 19.3 A BV-broadcast-based binary consensus algorithm for the model    $B A M P_{n,t}[n\,>$   $3t,\mathbf{CC}]$   (code for    $p_{i}$  ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 392

 19.4 From multivalued to binary Byzantine consensus in    $B A M P_{n,t}[t~<~n/3,\mathrm{BBC}]$  (code of  $p_{i}$  ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397

 19.5 VBB-broadcast on top of reliable broadcast in    $B A M P_{n,t}[t<n/3]$   (code of  $p_{i}$  ) . . . 400

 19.6 From multivalued to binary consensus in    $B A M P_{n,t}[t<n/3,\mathrm{BBC}]$   (code for  $p_{i}$  ) . . 403

 19.7 Local blockchain representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 405  

20.1 An order two projective plane . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 414

 20.2 Structure of a cryptography system . . . . . . . . . . . . . . . . . . . . . . . . . . 415

 20.3 Hypercubes  $\mathrm{H}(1)$  ,  $\mathrm{H}(2)$  , and  $\mathrm{H(3)}$   . . . . . . . . . . . . . . . . . . . . . . . . . . . 419

 20.4 Hypercube  $\mathrm{H}(4)$  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 420

 20.5 The de Bruijn directed networks dB(2,1), dB(2,2), and dB(2,3) . . . . . . . . . . . . 421

 20.6 Kautz graphs   $\mathrm{K}(2,1)$   and   $\mathbf{K}(2,2)$  . . . . . . . . . . . . . . . . . . . . . . . . . . . 421

 20.7 Kautz graph   $\mathbf{K}(2,3)$  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 422  

# Tables  

1.1 Four classic fault-prone distributed computing models . . . . . . . . . . . . . . . . . . 16

 4.1 Comparing the three Byzantine reliable broadcast algorithms . . . . . . . . . . . . . . 72

 6.1 Cost of algorithms implementing read/write registers . . . . . . . . . . . . . . . . . . 115

 9.1 Crash vs Byzantine failures: cost comparisons . . . . . . . . . . . . . . . . . . . . . . 163

 10.1 Crash pattern . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180

 10.2 Missing messages due to the crash of    $p_{i}$   . . . . . . . . . . . . . . . . . . . . . . . . . 185

 11.1 Examples of (maximal and non-maximal) legal conditions . . . . . . . . . . . . . . . 203

 14.1 Upper bounds on the number of faulty processes for consensus . . . . . . . . . . . . . 245

 16.1 Read/write register vs consensus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314

 20.1 Deﬁning quorums from a  ${\sqrt{n}}\times{\sqrt{n}}$   grid . . . . . . . . . . . . . . . . . . . . . . . . . 413

 20.2 Number of vertices for    $D=\Delta=4$  , 6, 8, 10 . . . . . . . . . . . . . . . . . . . . . . . 422  

# Chapter 1  

# A Few Deﬁnitions and Two Introductory Examples  

This chapter introduces basic deﬁnitions and basic computing models associated with fault-tolerant message-passing distributed systems. It also presents two simple distributed computing problems, whose aim is to give a ﬁrst intuition of what can be done and what cannot be done in message-passing systems prone to failures. Consequently, this chapter must be considered as an introductory warm-up chapter.  

Keywords Algorithm, Automaton, Asynchronous system, Byzantine process, Communication graph, Distributed algorithm, Distributed computing model, Distributed computing problem, Fair communication channel, Liveness property, Message adversary, Message loss, Non-determinism, Process crash failure, Process mobility, Safety property, Spanning tree, Synchronous system.  

# 1.1 A Few Deﬁnitions Related to Distributed Computing  

Distributed computing “Distributed computing was born in the late 1970s when researchers and practitioners started taking into account the intrinsic characteristic of physically distributed systems. The ﬁeld then emerged as a specialized research area distinct from networking, operating systems, and parallel computing.  

Distributed computing  arises when one has to solve a problem in terms of distributed entities (usually called processors, nodes, processes, actors, agents, sensors, peers, etc.) such that each entity has only a partial knowledge of the many parameters involved in the problem that has to be solved.”  

The fact the computing entities and their individual inputs are distributed is not under the control of the programmers but is imposed on them. From an architectural point of view, this is expressed in  Fig. 1.1 , where a pair    $\langle p_{i},i n_{i}\rangle$  denotes a computing entity  $p_{i}$   and its associated input    $i n_{i}$   (this is formalized with the notion of a  distributed task  introduced in Section 1.3, page 12).  

The concept of a sequential process A  sequential algorithm  is a formal description of the behavior of a sequential state machine: the text of the algorithm states the transitions that have to be sequentially executed. When written in a speciﬁc programming language, an algorithm is called a  program .  

The concept of a  process  was introduced to highlight the difference between an algorithm as a text and its execution on a processor. While an algorithm is a text that describes statements that have to be executed (such a text can also be analyzed, translated, etc.), a process is a “text in action”, namely the dynamic entity generated by the execution of an algorithm (program) on a processor (computing device). At any time, a process is characterized by its state (which comprises, among other things, the current value of its program counter). A sequential process is a process deﬁned by a single control  

![](images/f16bcd92a7beecd0c35b2a4015f2ae746faf0d540e9d3b0456a7934709d00d3b.jpg)  
Figure 1.1: Basic structure of distributed computing  

ﬂow: its behavior is managed by a single program counter, which means it executes a single step at a time.  

Distributed system As depicted in  Fig. 1.1 , a distributed system is made up of a collection of distributed computing units, each one abstracted through the notion of a  process , interconnected by a communication medium. As already said, the distribution of the processes (computing units) is not under the control of the programmers, it is imposed on them.  

In this book we assume that the set of processes is static. Composed of  $n$   processes, it is denoted  $\Pi=\{p_{1},...,p_{n}\}$  , where each  $p_{i}$  ,  $1\leq i\leq n$  , represents a distinct process. The integer  $i$   denotes the index  of process  $p_{i}$  , i.e., the way an external observer can distinguish processes. It is nearly always assumed that each process  $p_{i}$   has its own identity, which is denoted    $i d_{i}$  . In a lot of cases    $i d_{i}=i$  .  

The processes are assumed to cooperate on a common goal, which means that they exchange information in one way or another. This book considers that the processes communicate by exchanging messages on top of a communication network (see for example  Fig. 1.2 ). Hence, the automaton associated with each process provides it with basic point-to-point send and receive operations.  

Communication medium The processes communicate by sending and receiving  messages  through channels . A channel can be reliable (neither message loss, creation, modi cation, nor duplication), or unreliable. Moreover, a channel can be synchronous or asynchronous.  Synchronous  means that there is an upper bound on message transfer delays, while  asynchronous  means there is no such bound. In any case, an algorithm must specify the properties it assumes for channels. As an example, an asynchronous reliable channel guarantees that each message takes a ﬁnite time to travel from its sender to its receiver. Let us notice that this does not guarantee that messages are received in their sending order. A channel satisfying this last property is called a  ﬁrst in ﬁrst out  (FIFO) channel.  

Each channel is assumed (a) to be bidirectional (it can carry messages in both directions) and (b) to have an inﬁnite capacity (it can contain any number of messages, each of any size).  

Each process  $p_{i}$   has a set of neighbors, denoted  neighbors i . According to the context, this set contains either the local identities of the channels connecting  $p_{i}$   to its neighbor processes or the identities of these processes.  

Structural view It follows from the previous deﬁnitions that, from a structural point of view, a distributed system can be represented by a connected undirected graph  $G=(\Pi,C)$   (where  $C$   denotes the set of channels). Three types of graphs are of particular interest ( Fig. 1.2 ):  

•  A  ring  is a graph in which each process has exactly two neighbors with which it can communicate directly, a left neighbor and a right neighbor.  

•  A  tree  is a graph that has two noteworthy properties: it is acyclic and connected (which means that adding a new channel would create a cycle, while suppressing a channel would disconnect it). •  A  fully connected  graph is a graph in which each process is directly connected to every other process. (In graph terminology, such a graph is called a clique.)  

![](images/0a66828233e3f9a5da2d8b2723a87a8b457309987f7d86b2df2eec408ecfa141.jpg)  
Figure 1.2: Three graph types of particular interest  

Distributed algorithm A  distributed algorithm  is a collection of    $n$   automata, one per process. An automaton describes the sequence of steps executed by the corresponding process.  

In addition to the power of a Turing machine, an automaton is enriched with two communication operations which allows it to send a message on a channel or receive a message on any channel. The operations are denoted “ send () ” and “ receive () ”.  

Synchronous algorithm A distributed  synchronous  algorithm is an algorithm designed to be executed on a synchronous distributed system. The progress of such a system is governed by an external global clock, denoted  $R$  , whose domain is the sequence of increasing integers. The processes collectively execute a  sequence of rounds , each round corresponding to a value of the global clock.  

During a round, a process sends a message to a subset of its neighbors. The fundamental property of a  synchronous  system is that a message sent by a process during a round  $r$   is received by its destination process during the very same round  $r$  . Hence, when a process proceeds to the round    $(r+1)$  , it has received (and processed) all the messages that have been sent to it during round    $r$  , and it knows the same holds for any process.  

Space/time diagram A distributed execution can be graphically represented by a  space/time diagram . Each sequential progress is represented by an arrow from left to right, and a message is represented by an arrow from the sending process to the destination process.  

The space/time diagram on the left of  Fig. 1.3  represents a synchronous execution. The vertical lines are used to separate the successive rounds. During the ﬁrst round,  $p_{1}$   sends a message to  $p_{3}$  , and  $p_{2}$   sends a message to  $p_{1}$  , etc.  

![](images/d107ce97753c135c5d6c71b8d89b7bf81a396f5c134b41f52db1ea20ec68dc8e.jpg)  
Figure 1.3: Synchronous execution (left) vs. asynchronous execution (right)  

Asynchronous algorithm A distributed  asynchronous  algorithm is an algorithm designed to be executed on an asynchronous distributed system. In such a system, there is no notion of an external time, which is why asynchronous systems are sometimes called  time-free  systems.  

In an asynchronous algorithm, the progress of a process is ensured by its own computation and the messages it receives. When a process receives a message, it processes the message and, according to its local algorithm, possibly sends messages to its neighbors.  

A process processes one message at a time. This means that the processing of a message cannot be interrupted by the arrival of another message. When a message arrives, it is added to the input buffer of the destination process  $p_{j}$  , and remains in it until an invocation of  receive ()  by  $p_{j}$   returns it.  

The space/time diagram of a simple asynchronous execution is depicted on the right of  Fig. 1.3 . One can see that, in this example, the messages from    $p_{1}$   to    $p_{2}$   are not received in their sending order. Hence, the channel from  $p_{1}$   to    $p_{2}$   is not a FIFO (ﬁrst in ﬁrst out) channel. It is easy to see from the ﬁgure that a synchronous execution is more structured (i.e., synchronized) than an asynchronous execution.  

Synchronous round vs asynchronous round In the synchronous model, the rounds, and their progress, belong to the model. In the asynchronous model, rounds are not given for free, but can be built by the processes. Nevertheless, when a process terminates a round    $r$  , it cannot conclude that the other processes are simultaneously doing the same. When there are failures, it cannot even conclude that all other processes will attain the round    $r$   it is executing.  

Event and execution An  event  models the execution of a step issued by a process, where a step is either a local step (communication-free local computation), or a communication step (the sending of a message, or the reception of a message). An  execution    $E$   is a partial order on the set of events produced by the processes.  

•  In the context of a synchronous system,  $E$  the processes, such that all the events occurring in a round  $r$   precede all the events of the round  $(r+1)$  , and, inside every round, all sending events, precede all reception events, which in turn precede all local events executed in this round. •  In the context of an asynchronous system,  $E$   is the partial order on the events produced by the processes such that, for each process,    $E$   respects the total order on its events, and, for any message  $m$   sent by a process  $p_{i}$   to a process  $p_{j}$  , the sending of  $m$   event occurs before its reception event by  $p_{j}$  .  

Process failure models Two main process failures models are considered in this book:  

•  Crash  failures. A process commits a crash failure when it prematurely stops its execution. Until it crashes (if it ever crashes), a process correctly executes its local algorithm. •  Byzantine  failures. A process commits a Byzantine failure when it does not follow the behavior assigned to it by its local algorithm. This kind of failure is also called  arbitrary  failure (sometimes known as  malicious  when the failure is intentional). Let us notice that crash failures (which are an unexpected deﬁnitive halt) are a proper subset of Byzantine failures. A simple example of a Byzantine failure is the the following: while it is assumed to send the same value to all processes, a process sends different values to different subsets of processes, and no value at all to other processes. This is a typical Byzantine behavior. Moreover, Byzantine processes can collude to foil the processes that are not Byzantine.  

From a terminology point of view, let us consider an execution    $E$   (an execution is also called a run). The processes that commit failures are said to be  faulty  in    $E$  . The other processes are said to be  correct  or  non-faulty  in    $E$  . It is not known in advance if a given process is correct or faulty, this is speciﬁc to each execution. Given a process failure model, the model parameter    $t$   is used to denote the maximal number of processes that can be faulty in an execution.  

Channel failure model Thanks to error-detecting/correcting codes, corrupted messages can be corrected, and received correctly. If a corrupted message cannot be corrected, it can be discarded, and then appears as a lost message. This means that, in practice, the important channel failure is the possibility to lose messages. These notions will be investigated in depth in Chapter 3, under the name fair channel  assumption. Intuitively, fair channels experiences uncontrolled transient periods during which messages are lost.  

Solving a problem A problem is deﬁned by a set of properties (see examples in the two next sections). One of these properties (usually called  liveness  or  termination ) states that “something happens”, i.e., a result is computed. The other properties are  safety  properties (according to what they state, they are called  validity, agreement, integrity , etc.). The safety properties state that “nothing bad happens”, consequently they describe properties that must never be violated (invariants). The decomposition of the deﬁnition of a problem into several properties facilitates both its understanding (as a problem) and the correctness proof of the algorithms that claim to solve it.  

An  algorithm solves a problem  in a given computing model  $M$   if, assuming the inputs are correct, there is a proof showing that any run of the algorithm in    $M$   satisﬁes all the properties deﬁning the problem. (Observe that an algorithm designed for a model    $M$   is not required to work when executed   in a model    $M^{\prime}$  which does not satisfy the requirements of    $M$  .)  

# 1.2 Example 1: Common Decision Despite Message Losses  

This section and the next one present two simple distributed computing problems in systems where no process is faulty, but messages can be lost. Their aim is to make the readers familiar with basic issues of fault-tolerant distributed computing, and, given a distributed computing model, help them to have a ﬁrst intuition of what can be done in this model, and what cannot be done. Let us remember that a model deﬁnes an abstraction level. It has to be accurate enough to capture the important phenomena that do really occur, and abstract enough to allow reasoning on the runs of the algorithms executed on top of it.  

# 1.2.1 The Problem  

This problem concerns an irrevocable decision-making by two processes. It seems to have its origin in the design of communication protocols, as presented by E.A. Akkoyunlu, E. Ekanadham, and R.V. Huber (1975). It then appeared in databases, where it was formalized by J. Gray (1978) under the name  The two generals  problem (there are variants of this problem, e.g., in synchronous systems).  

A metaphor The name of the problem comes from the following analogy. Let us consider two hilltops    $T1$   and  $T2$   separated by a valley  $V$  . There are two armies    $A$   and  $B$  . The army    $A$   is composed of two divisions    $A1$   and    $A2$  , each with a general, the general-in-chief being located in division    $A1$  . Moreover,    $A1$   is camping on  $T1$  , while    $A2$   is camping on  $T2$  . Army    $B$   is in between, camping in the valley    $V$  . The only way  $A1$   and  $A2$   can communicate is by sending messengers who need to traverse the valley  $V$  . But messengers can be captured by army    $B$  , and never arrive. It is nevertheless assumed that not all messengers sent by  $A1$   and    $A2$   can be captured.  

The generals of army  $A$   previously agreed on two possible battle plans  bp 1  and    $b p2$  , but, according to his analysis of the situation, it is up to the general-in-chief to decide which plan must be adopted. To this end, the general-in-chief must communicate his decision to the general of  $A2$   so that they both adopt the same battle plan (and win).  

The problem consists in designing a distributed algorithm (a sequence of message exchanges initiated by the general-in-chief in  $A1$  ), at the end of which (a)  $A2$   knows the battle plan selected by    $A1$  , and (b) both  $A1$   and  $A2$   know they no longer have to send or receive messages.  

System model Let    $p_{1}$   and  $p_{2}$   be two processes representing    $A1$   and    $A2$  , respectively, connected by a bi-directional asynchronous channel controlled by the army    $B$  . The processes are assumed to never fail. While no message can be modiﬁed (corrupted), the channel is asynchronous and unreliable in the sense that messages can be lost (a message loss represents a messenger captured by army    $B$  ). It is nevertheless assumed that not all messages sent by    $p_{1}$   to  $p_{2}$   (and by  $p_{2}$   to    $p_{1}$  ) can be lost (otherwise, there is a possible run in which the processes could not communicate, making the problem impossible to solve). As mentioned previously, a channel can experience unexpected transient periods during which messages are lost.  

Formalizing the problem As the general-in-chief of army    $A$   is in    $A1$  , process    $p_{1}$   activates the sequence of message exchanges by sending the message  DECIDE  $(b p)$   to  $p_{2}$  , where    $b p$   is the number of the chosen battle plan.  

For  $i\in\{1,2\}$  , let  $d o n e_{i}$   be a local variable of  $p_{i}$   initialized to  no  (for the corresponding process, no decision has been made). Hence, representing a global state by the pair    $\langle d o n e_{1}$  , done 2 ⟩ , the initial global state is the pair    $\langle\mathsf{n o},\,\mathsf{n o}\rangle$  . At the end of its execution, the distributed algorithm must stop in the global state    $\langle\mathtt{y e s},\ \mathtt{y e s}\rangle$  . When    $d o n e_{i}=\tt y e s$  , process  $p_{i}$   knows (a) that each process knows the selected battle plan, and (b) there is no need for messages to be exchanged, namely each process terminates its local algorithm (see  Fig. 1.4 ). This is captured by the following properties:  

•  Validity. A ﬁnal global state cannot contain both  yes  and  no .  

•  Liveness. If  $p_{1}$   activates the algorithm, it eventually and permanently enters the local state  $d o n e_{1}=\mathbf{y}\mathbf{e}\mathbf{s}$  .  

The validity property states which are the correct outputs of the algorithm: in no case    $p_{1}$   and  $p_{2}$   are allowed to disagree. The liveness property states that, if  $p_{1}$   starts the algorithm, it must eventually progress. (Let us notice that, it then follows from the validity property that both processes must progress.)  

![](images/9bd341c5ba56a6cf166da76cc88e71a73c272ff93fb33c2dfa4de981940285e9.jpg)  
Figure 1.4: Algorithm structure of a common decision-making process  

A practical instance of the problem Let us consider two processes    $p_{1}$   and    $p_{2}$   communicating through an unreliable fair channel. Let us assume that, after some time, they want to close their working session; this disconnection being initiated by  $p_{1}$  . Hence, in the previous parlance, they are both in the local state  $d o n e_{i}\;=\;\mathsf{n o}$  , and they have to progress to the global state    $\langle\mathtt{y e s},\ \mathtt{y e s}\rangle$  .  

As the reader can see, the closing session problem is nothing other than an instance of the previous “common decision-making in the presence of message losses” problem.  

# 1.2.2 Trying to Solve the Problem: Attempt 1  

Starting with  $p_{1}$  Let us try to design an algorithm for    $p_{1}$  . As messages (but not all) sent by  $p_{1}$   to  $p_{2}$  can be lost, a simple idea is to require  $p_{1}$   to repeatedly send a message denoted  DECIDE (  $(b p)$   to  $p_{2}$   until it has received an acknowledgment (  $\mathit{b p}$   is the – dynamically deﬁned by  $p_{1}$   – number of the selected battle plan):  

$d o n e_{1}\gets\mathsf{n o};$   $b p\leftarrow$  selected battle plan    $\in\{1,2\}$  ; repeat  send  DECIDE  $(b p)$   to  $p_{2}$   until  ACK ( DECIDE )  received from    $p_{2}$   end repeat ;  $d o n e_{1}\gets\mathtt{y e s}$  .  

Continuing with  $p_{2}$  While in the state    $d o n e_{2}=\texttt{n o}$  ,    $p_{2}$   receives the message  DECIDE  $(b p)$  , it sends back to  $p_{1}$   the acknowledgment message  ACK ( DECIDE ), but this acknowledgment message can be lost. Hence  $p_{2}$   must resend  ACK ( DECIDE ) until it knows a copy of it has been received by  $p_{1}$  . Consequently, the local algorithm of    $p_{1}$   must be enriched with a statement sending an acknowledgment message back to  $p_{2}$   that we denote    $\scriptstyle\mathrm{ACK}^{2}$  ( DECIDE ). We then obtain the following local algorithms for    $p_{2}$  :  

$d o n e_{2}\gets\mathsf{n o};$  wait (message  DECIDE  $(b p)$   from  $p_{1.}$  ); repeat  send  ACK ( DECIDE )  to  $p_{1}$   until  $\mathrm{ACK^{2}}$  ( DECIDE )  received from  $p_{1}$   end repeat ;  $d o n e_{2}\gets\mathtt{y e s.}$  .  

Returning to  $p_{1}$  As    $p_{1}$   is required to send the message  $\mathrm{ACK}^{2}(\mathrm{DECIDE})$   to  $p_{2}$  , and this message  must be received  by  $p_{2},p_{1}$     $p_{2}$  . As we have seen, the only way for  $p_{1}$   to know if  $p_{2}$   received  $\mathrm{ACK^{2}}$  ( DECIDE ) is to receive an acknowledgment message  $\mathrm{ACK^{3}}$  ( DECIDE ) from  $p_{2}$  . We then have the following enriched algorithm for    $p_{1}$  :  

$d o n e_{1}\gets\mathsf{n o};$   $b p\leftarrow$  selected battle plan number    $\in\{1,2\}$  ; repeat  send  DECIDE  $(b p)$   to  $p_{2}$   until  ACK ( DECIDE )  received from    $p_{2}$   end repeat ; repeat  send    $\scriptstyle\mathrm{ACK}^{2}$  ( DECIDE )  to  $p_{2}$   until  $\mathrm{ACK^{3}}$  ( DECIDE )  received from  $p_{2}$   end repeat ;  $d o n e_{1}\gets\mathtt{y e s}$  .  

And so on forever As the reader can see, this approach does not work. An inﬁnity of distinct acknowledgment messages is needed, each acknowledging the previous one.  

# 1.2.3 Trying to Solve the Problem: Attempt 2  

Trying to modify both local algorithms In order to prevent the sending of an inﬁnite sequence of different acknowledgment messages, let us consider the same algorithm as before for    $p_{1}$  , namely,  $p_{1}$  sends  $\scriptstyle\mathrm{DEDE}\left(b p\right)$   until it knows that    $p_{2}$   has received it. When this occurs,    $p_{1}$   knows that   ${}^{**}\!p_{2}$   knows the number of the decided battle plan”, and  $p_{1}$   terminates this local algorithm:  

$d o n e_{1}\gets\mathtt{n o};$  ;  $b p\leftarrow$   ← selected battle plan    $\in\{1,2\}$  ; repeat  send  DECIDE  $(b p)$   to  $p_{2}$   until  ACK ( DECIDE )  received from    $p_{2}$   end repeat ;  $d o n e_{1}\gets\mathtt{y e s}$  .  

Let us now modify the algorithm of    $p_{2}$   according to the previous modi cation of    $p_{1}$  :  

$d o n e_{2}\gets\mathtt{n o}$  ; wait (message  DECIDE  $(b p)$   from  $p_{1.}$  ); repeat  send  ACK ( DECIDE )  to  $p_{1}$   each time  DECIDE  $(b p)$   received from  $p_{1}$   end repeat ;  $d o n e_{2}\gets\mathtt{y e s}$  .  

When it receives a copy of the message    $\scriptstyle\mathrm{DEDE}\left(b p\right)$  ,    $p_{2}$   knows that “both  $p_{1}$   and    $p_{2}$   know the number of the battle plan”, but it cannot be allowed to proceed to the local state    $d o n e_{2}=\tt y e s$  . This is because, as  $p_{1}$   needs to know that “both  $p_{1}$   and  $p_{2}$   know the number of the battle plan”,    $p_{2}$   needs to send an acknowledgment  ACK ( DECIDE ) each time it receives a copy of the message    $\mathrm{DEDEICIDE}(b p)$  . As not all messages are lost, this ensures that    $p_{1}$   will know that “both    $p_{1}$   and    $p_{2}$   know the battle plan” despite message losses. Even if  $p_{1}$   sends a ﬁnite number of copies of    $\scriptstyle\mathrm{DEDE}\left(b p\right)$  , and none of them are lost, the “repeat” statement inside  $p_{2}$   cannot be bounded. This is because    $p_{2}$   can never know how many copies of the message  DECIDE  $(b p)$   it will receive. Due to the fact that not all messages are lost, it knows only that this number is ﬁnite, but never knows its value. This depends on the channel, and the behavior of the channel is not under the control of the processes. Hence, this tentative version does not ensure that both processes terminate their algorithm.  

Which raises the fundamental question: is there another approach that can successfully solve the problem, or is the problem unsolvable?  

A sequence of messages instead of a common decision Before answering the question, let us consider a similar problem, in which    $p_{1}$   wants to send to    $p_{2}$   an inﬁnite sequence of messages    $m_{1}$  ,  $m_{2}$  , ...,  $m_{x}$  , ... (each message    $m_{x}$   carrying its sequence number    $x$  ). In this case, starting from    $x=1$  , process  $p_{1}$   repeatedly sends  $m_{x}$   to  $p_{2}$  , until it receives an acknowledgment message    $\operatorname{ACK}(x)$   from  $p_{2}$  . When it receives such a message,  $p_{1}$   proceeds to the message  $m_{x+1}$  .  

This algorithm is well-known in communication protocols, where, in addition, the acknowledgments from  $p_{2}$   to  $p_{1}$   are actually replaced by a sequence of messages  $m_{1}^{\prime}$   $\imath_{1}^{\prime},m_{2}^{\prime},...,m_{x}^{\prime},.$  , ... that  $p_{2}$    wants to send to    $p_{1}$  . As we can see, in addition to carrying its own data value, the message    $m_{x}^{\prime}$    acts as an acknowledgment message    $\operatorname{ACK}(x)$   (and  $m_{x+1}$   acts as an acknowledgment message for    $m_{x}^{\prime}$  ).  

# 1.2.4 An Impossibility Result  

While it is possible to design a simple algorithm transmitting an inﬁnite sequence of messages on top of a channel which can experience transient message losses (an unreliable fair channel), it appears that it is impossible to design an algorithm ensuring common decision-making on top of such an unreliable channel.  

Theorem 1.  There is no algorithm solving the common decision-making problem between two processes, if the underlying communication channel is prone to arbitrary message losses.  

Proof  Let us ﬁrst observe that any algorithm solving the problem is equivalent to an algorithm    $A$   in which  $p_{1}$   and    $p_{2}$   execute successive phases of message exchanges, where, in each phase, a process sends a message to the other process.  

The proof is by contradiction. Let us assume that there are phase-based algorithms that solve the problem, and, among them, let us consider the algorithm    $A$   that uses the fewest communication phases. As    $A$   terminates, there is a last phase during which a message is sent. Without loss of generality, let us assume this message    $m$   is sent by  $p_{1}$  . Moreover, assume    $m$   is not lost.  

•  The last statement executed by  $p_{1}$   cannot depend on whether or not  $m$   is received by  $p_{2}$  . This is because, as    $m$   is the last message sent, the fact that it has been lost or received by  $p_{2}$   cannot be known by    $p_{1}$  . Hence, the last statement executed by  $p_{1}$   cannot depend on    $m$  . •  Similarly, the last statement executed by  $p_{2}$   cannot depend on    $m$  . This is because, as    $m$   could be lost and this is not known by  $p_{1}$  , the last statement of  $p_{1}$   must be as if    $m$   was lost, and cannot consequently depend on    $m$  .  

As the last statements of both  $p_{1}$   and    $p_{2}$   cannot depend on    $m$  , this message is useless. Hence, we obtain a terminating execution in which one less message is sent. This execution can be produced by an algorithm  $A^{\prime}$    which is the same as  $A$   without the sending of the message  $m$  . Hence,    $A^{\prime}$    contradicts the fact that    $A$   solves the problem with the fewest number of communication phases. 2 Theorem  1  

The notion of in distinguish ability Considering the tentative algorithm outlined in Section 1.2.2, let us assume that no messages are lost (but remember that neither  $p_{1}$   nor  $p_{2}$   can know this). Even in such a run, the tentative algorithm never terminates.  

As the reader can check, the difﬁculty for a process is its inability to distinguish what actually happened (in this case no message loss) from what could have happened (message losses). Designing distributed algorithms able to cope with this type of uncertainty is one of the main d if cul ties of distributed computing in the presence communication failures.  

# 1.2.5 A Coordination Problem  

Let us consider the following coordination problem. Two processes are connected by a bidirectional communication channel. As previously, the processes are assumed not to fail, but the channel is prone to transient failures during which messages are lost. Each process can execute two actions,    $A C1$   and  $A C2$  , which both processes know in advance.  

The problem consists in designing a distributed algorithm satisfying the following properties:  

•  Integrity. Each process executes at most one action. •  Agreement. The processes do not execute different actions. •  Liveness. Each process executes at least one action.  

Integrity prevents a process from executing both actions. Combined with liveness, it follows that each process executes exactly one action.  

Integrity and agreement are safety properties: they state what must never be violated by an algorithm solving the problem. Let us observe that the safety properties are trivially satisﬁed by an algorithm doing nothing. Hence, the necessity of the liveness property which states that the algorithm must force the processes to progress.  

Despite the fact that both processes never fail, this problem is impossible to solve. Its impossibility proof is Exercise 2 (see Section 1.8).  

# 1.3 Example 2:  

# Computing a Global Function Despite a Message Adversary  

# 1.3.1 The Problem  

Let us assume that each process  $p_{i}$   has an input  $i n_{i}$  , initially known only by the process. Moreover, it is assumed that each process knows    $n$  , the total number of processes. Each process  $p_{i}$   must compute its own output    $o u t_{i}$   such that    $o u t_{i}\,=\,f_{i}(i n_{1},.\,.\,.\,,i n_{n})$  . According to what must be computed, the  

![](images/41a18474dd806bc3539f3e55f1a7ba67c4492502ad79922ec61e1a6fe5a8b219.jpg)  
Figure 1.5: A simple distributed computing framework  

functions    $f_{i}()$   can be the same function or different functions. A structural view is illustrated in Fig. 1.5 .  

The important point here is that we consider a distributed system context. The fact that there are    $n$   processes is not a design choice but a fact imposed on the designer of the algorithm: there are    $n$   computing entities, geographically distributed. (As a simple example, suppose that each  $p_{i}$  is a temperature sensor, and some sensors must compute the highest temperature, other sensors the lowest temperature, and the rest of the sensors the average temperature.) The case    $n=1$   is a very particular case for which the problem boils down to the writing of a sequential algorithm computing  $o u t_{1}=f_{1}(i n_{1})$  .  

In the distributed parlance, such a problem is sometimes called a  distributed task , deﬁned by a relation    $T()$   associating a set of possible output vectors  $T(I N)$   with each possible input vector    $I N$  , namely,    $O U T\in T(I N)$  .  

Deﬁning the problem with properties Given a set of functions    $f_{i}()$  , let    $i n_{i}$   be the input of    $p_{i}$  . Any algorithm solving the problem must satisfy the following properties:  

•  Validity. If process  $p_{i}$   returns  $o u t_{i}$  , then    $o u t_{i}=f_{i}(i n_{1},.\,.\,.\,,i n_{n})$  . •  Liveness. Each process    $p_{i}$   returns a result  $o u t_{i}$  .  

As previously explained, the validity property states that, if a process returns a result, this result is correct, while the liveness property states that the computation terminates.  

# 1.3.2 The Notion of a Message Adversary  

Reliable synchronous model Let    $S M P_{n}[\varnothing]$   be the synchronous message-passing system model in which no process is faulty, each process  $p_{i}$   has a set of neighbors ( neighbor i ), and the communication graph is connected (there is a path from any process to any other process). In this model the processes execute a sequence of rounds, and each round  $r$   comprises three phases that follow the pattern “send; receive; compute”:  

•  First each process sends a message to its neighbors. •  Then, each process waits for the messages that have been sent to it during the current round. •  Finally, according to its current local state and the messages it received during the current round, each process computes its new local state.  

As already indicated, the fundamental property of this model is its synchrony: each message is received in the round in which it was sent. Moreover, the progress from a round    $r$   to the next round  $r+1$   is automatic, i.e., it is not under the control of the processes, but provided to them for free by the model. From an operational point of view, there is a global round variable    $R$   that any process can read, and whose progress is managed by the system (see left part of  Fig. 1.3 ).  

The notion of a message adversary A  message adversary  is a daemon that, at every round, is allowed to suppress a subset of channels (i.e., it withdraws and discards the messages sent on these channels).  

To put it differently, the message adversary deﬁnes the actual communication graph associated with every round. Let    $G(r)$   be the undirected communication graph associated with round    $r$   by the adversary. This means that, at any round  $r$  , the message adversary is allowed to drop the messages sent on any channel that does not belong to    $G(r)$  . Hence, from the point of view of the processes these messages are lost. Given any pair of distinct rounds  $r$   and    $r^{\prime}$  ,  $G(r)$   and    $G(\boldsymbol{r}^{\prime})$   are not necessarily related one to the other. Moreover, the adversary is not prevented from being “omniscient”, namely it can deﬁne dynamically the graphs  $G(1)$  , ...,  $G(r)$  ,    $G(r+1)$  , etc. For example, nothing prevents it from knowing the local states of the processes at the end of a round  $r$  , and using this information to deﬁne    $G(r+1)$  . Finally,  $\forall r$  , no process ever knows  $G(r)$  . Given an un constrained message adversary AD, and a system involving four processes, an example of three possible consecutive communication graphs is depicted in  Fig. 1.6 .  

![](images/dedcc97d317d6c2c01015c5e1a027d2dae721945e756896d71dbf8ddeaf8d1cb.jpg)  
Figure 1.6: Examples of graphs produced by a message adversary  

If the message adversary can suppress all messages at every round, no non-trivial problem can be solved, whatever the individual computational power of each process. At the other extreme if, at any round, the message adversary cannot suppress messages, it has no power (we have then the reliable synchronous model    $S M P_{n}[\varnothing])$  ). Hence, the question: How can we restrict the power of a message adversary, so that, while it can suppress plenty of messages, it cannot prevent each process from learning the inputs of the other processes? As we are about to see, the answer to this question is a matter of graph connectivity, every round being taken individually.  

The reliable synchronous model    $S M P_{n}[\emptyset]$  , weakened by an adversary AD, is denoted  $S M P_{n}[\mathrm{AD}]$  .  

# 1.3.3 The TREE-AD Message Adversary  

The TREE-AD message adversary At every round, this message adversary can suppress the messages on all the channels, except on the channels deﬁning a spanning tree involving all the processes. As an example, when considering  Fig. 1.6 , which involves four processes,  $G(1)$   and    $G(3)$   deﬁne spanning trees including all the processes, while    $G(2)$   does not (it includes two disconnected spanning trees, one involving three processes, the other one being a singleton tree).  

A TREE-AD-tolerant algorithm Fig. 1.7  describes an algorithm that works in the weakened synchronous model    $S M P_{n}$  [ TREE-AD ] . Each process  $p_{i}$   has an input  $i n_{i}$   known only by itself, and manages an array    $k n o w n_{i}[1..n]$  , initialized to    $[\bot,...,\bot]$  , such that  $k n o w n_{i}[j]$   will contain the input value of    $p_{j}$  .  

Let us assume that    ${\perp}\,<\,i n_{j}$   for any    $j\,\in\,\{1,n\}$   (this is only to simplify the writing of the algorithm). The operation “ broadcast    $\mathrm{MSG-TYPE}(v a l)"$   issued by  $p_{i}$  , where  MSG - TYPE  is a message type and  val  the data carried by the message, is a simple macro-o ration for “ for each    $k\in$  neighbor  $\cdot_{S_{i}}$   do send  MSG - TYPE  $(v a l)$   to  $p_{k}$   end for ”. Let us remember that  R  is the model-provided round generator, which automatically ensures the progress of the computation.  

![](images/f7b36c6ca42b272b958de3fc4dbc15436124004bb6728dd62ff2ea594458919d.jpg)  
Figure 1.7: Distributed computation in    $S M P_{n}$  [ TREE-AD ]  (code for  $p_{i}$  )  

A process  $p_{i}$   ﬁrst initializes    $k n o w n_{i}[1..n]$   (line 1). Then, simultaneously with all processes, it enters a sequence of synchronous rounds (lines 2-8), at the end of which it will know the input values of all the processes, and consequently will be able to return its local result (line 9).  

As already stated, the global variable    $R$   is provided by the synchronous model, and each message is either suppressed by the message adversary or received in the round in which it was sent. During a round, a process    $p_{i}$   ﬁrst sends its current knowledge on the process inputs to its neighbors, which is currently saved in its local array  known i  (line 4). Then it updates its local array    $k n o w n_{i}$   according to what it learns from the messages it receives during the current round (lines 5-7). The sequence of rounds is made up of    $(n-1)$   rounds.  

Theorem 2.  Each process  $p_{i}$   returns a result  out i  (liveness), and this result is equal to    $f_{i}(i n_{1},...,i n_{n})$  (validity).  

Proof  Let us ﬁrst prove the liveness property. This is a direct consequence of the synchrony assumption. The fact that the current round number    $R$   progresses from  1  to    $n$   is ensured by the model (together with the property that a message that is not suppressed by the message adversary is received in the same round by its destination process).  

As far as the validity property is concerned, let us consider the input value  $i n_{i}$   of a process  $p_{i}$  . At the beginning of any round    $r$  , let us partition the processes into two sets: the set  they know i which contains all the processes that know    $i n_{i}$  , and the set  they do not know i  which contains the processes that do not know  $i n_{i}$  . Initially (beginning of round    $R=1$  ), we have  they know i  $\mathbf{\Psi}=\{i\}$  , and  they do not know  $v_{i}=\left\{1,...,n\right\}\setminus t h e y_{-}k n o w_{i}$  .  

![](images/c46f6440656bd09cda0060b60308c3746dd451d765ae4319b2315ff35c92404e.jpg)  
Figure 1.8: The property limiting the power of a TREE-AD message adversary  

Due to the fact that, at every round  $r$  , there is a spanning tree on which the message adversary does not suppress the messages, this tree includes a channel connecting a process belonging to  they know i to a process belonging to  they do not know i  ( Fig. 1.8 ). It follows that, if    $|t h e y_{-}k n o w_{i}|<n$  , there is at least one process  $p_{k}$   that moves from the set  they do not know i  to the set  they know i  during round  $r$  . (“  $\cdot_{p_{x}}$   knows    $i n_{i}{"}$   means    $k n o w n_{x}[i]=i n_{i}$  .) As there are    $(n-1)$   rounds, it follows that, by the end of the last round, we have    $|t h e y_{-}k n o w_{i}|\,=\,n$  . As this is true for any process    $p_{i}$  , it follows that any process  $p_{j}$   is such that  $i n_{j}$   is known by all processes by the end of the round    $(n-1)$  , which concludes the proof of the theorem. 2 Theorem  2  

Cost of the algorithm For the time complexity, assuming each round costs one time unit, the algorithm requires    $(n-1)$   time units.  

Let    $d$   the number of bits needed to represent any process input or  $\perp$  . (Note t  $d$   does not depend on the algorithm, but on the application that uses it.) Each message requires  nd  bits. Moreover, as there are    $(n\mathrm{~-~}1)$   rounds, and (assuming a process does not send a message to itself) the number of messages per round is uppe unded by    $(n\mathrm{~-~}1)n$  , which means that the bit complexity of the algorithm is upper bounded by  $n^{3}d$   bits.  

On the meaning of the TREE-AD message adversary It is easy to see that, if, at any round, the adversary can partition the set of    $n$   processes into two sets that can never communicate, as    $o u t_{i}$  depends on all the inputs, no process  $p_{i}$   can compute its output. In this sense, TREE-AD states that the system is never partitioned by messages losses that would prevent a process from learning the inputs of the other processes.  

It is possible to deﬁne a “stronger” adversary than TREE-AD, denoted TREE $\mathrm{AD}^{c}$  , which allows the problem to be solved. “Stronger” means a message adversary that, at some rounds, can disconnect the processes, and hence discard more messages than TREE-AD. Let    $c\geq n-1$   be a constant known by each process, and let us modify line 2 of the algorithm in  Fig. 1.7  so that now each process executes    $c$   rounds. TREE $\cdot_{ Ḋ }\mathrm{AD}^{c} Ḍ$  is deﬁned by the following constraint:  

$$
|\{r:\ 1\leq r\leq c:\ G(r)\ \mathrm{contains~a~spanning~tree}\ \}|\geq n-1.
$$  

TREE $\mathrm{AD}^{c}$  allows    $c-(n-1)$   rounds where the subsets of processes are disconnected. It is easy to see that the previous proof is still valid: eliminating a set of    $c-(n-1)$   rounds    $r$   including all the rounds in which    $G(r)$   does not contain a spanning tree, we obtain an execution that could have been produced by the algorithm in  Fig. 1.7 . As this is obtained by the same algorithm at the price of more rounds, this exhibits a compromise between “the power of the message adversary” and “the number of rounds that have to be executed”.  

# 1.3.4 From Message Adversary to Process Mobility  

In a very interesting way, the notion of a message adversary allows the capture of the mobility of processes in the reliable round-based synchronous system model    $S M P_{n}[\emptyset]$  . The movement of a process from a location    $L1$   to a location  $L2$   translates as the suppression of some channels and the creation of new channels when the system progresses from one round to the next.  

As an example, let us consider  Fig. 1.9 . There are six processes, and the ﬁrst three rounds are represented. For    $r=1,2,3$  ,  $G(r)$   describes the communication graph during round    $r$  . The move of a process is indicated by a dashed red arrow.  

After it has processed the message it received during round  $r\,=\,1$  , the movement of    $p_{3}$   entails the suppression of the channel linking    $p_{3}$   to  $p_{2}$  , and the creation of a new channel linking    $p_{3}$   to  $p_{4}$  . We then obtain the communication graph    $G(2)$  . Then, the simultaneous motion of    $p_{5}$   and    $p_{6}$   connects them to  $p_{3}$  , without disconnecting them, which produces  $G(3)$  .  

![](images/5cdd35968b3624bf7fbfa858b869248d010d5c304632ddac6405cff7deb00309.jpg)  
Figure 1.9: Process mobility can be captured by a message adversary in synchronous systems  

# 1.4 Main Distributed Computing Models Used in This Book  

Let us remember that    $n$   denotes the total number of processes, and    $t$   is an upper bound on the number of processes that can be faulty. In all cases it will be assumed that processing times are negligible with respect to message transfer delays; they are consequently considered as having a zero duration. Moreover, in the models deﬁned in this section, the underlying communication network is assumed to be fully connected (the associated communication graph is a clique).  

According to the process failure model and the synchrony/asynchrony model, we have four main distributed computing models, denoted as depicted in  Table 1.1  (  $C$   stands for crash,    $B$   stands for Byzantine, and    $M P$   stands for full graph message-passing). ∅ ]  means there are neither additional assumptions enriching the model, nor restrictions weakening it. Given a speciﬁc model, additional assumptions allow for the deﬁnition of stronger models, while restrictions allow for the deﬁnition of weaker models.  

Table 1.1: Four classic fault-prone distributed computing models 
![](images/c2101e3be9ee8bed7517a409dc346f08a850290b4e04a7ab7b2e7366b68ded72.jpg)  

Let us observe that, in these four basic models, the underlying network is reliable; hence, the main difﬁculty in solving a problem in any of them will come from the net effect of the synchrony/asynchrony of the network and the process failure model.  

To summarize the reading of a model deﬁnition:  

•  The ﬁrst letter states the process failure model (crash vs Byzantine). •  The second letter states the timing model (synchronous or asynchronous). •  The processes send and receive messages on a reliable complete communication graph. •  [ ∅ ]  means that this is the basic model considered. There are no other assumptions, and hence  $t$  can be any value in  [1 .  $.(n-1)]$  )  (it is always assumed that at least one process does not crash).  

Variants of the four previous basic models will be introduced in some chapters to address speciﬁc issues related to fault-tolerance. These variants concern two dimensions:  

•  Enriched model. As an example, the model    $C A M P_{n,t}[t\,<\,n/2]$   is the model    $C A M P_{n,t}[\varnothing]$  enriched with the assumption  $t<n/2$  , which means that there is always a majority of correct processes. Hence,    $C A M P_{n,t}[t<n/2]$   is a stronger model than    $C A M P_{n,t}[\emptyset]$  , where “stronger” means “more constrained in the sense it provides us with more assumptions”.  

•  Weakened Model. As an example, the model    $C A M P_{n,t}[\cdot\operatorname{FC}]$   is the model    $C A M P_{n,t}[\varnothing]$   weakened by the assumption FC (with states that the communication channels are no longer reliable but are only fair, see Chap. 3). A weakening assumption is preﬁxed by the sign “-” (to stress the fact the fact it weakens the model to which it is applied). •  Model with both enrichment and weakening. As an example, the model    $C A M P_{n,t}[\cdot$   FC ,   $t<$   $n/2]$   is the model    $C A M P_{n,t}[\varnothing]$   weakened by fair channels, and enriched by the assumption there is always a majority of correct processes. Failure detectors (such as the one introduced in Chap. 3) are a classic way to enrich a system. A failure detector is an oracle that provides each process with additional computability power. As an example,    $C A M P_{n,t}[-$   FC ,  FD1 ,  FD2 ]  denotes the model    $C A M P_{n,t}[\emptyset]$   weakened by fair channels, and enriched with the computability power provided by the failure detectors of the classes FD1 and FD2.  

All these notions will be explicited in Chap. 3, where they will be used for the ﬁrst time.  

# 1.5 Distributed Computing Versus Parallel Computing  

![](images/842556276cb4bbb2da6d5be73d02729192ff61bebed3e7e18a76faf836838a4a.jpg)  
Figure 1.10: Sequential or parallel computing  

Parallel computing When considering  Fig. 1.10 , a function    $f()$  , and an input parameter  $x$  , parallel computing addresses concepts, methods, and strategies which allow us to beneﬁt from parallelism (simultaneous execution of distinct threads or processes) when one has to implement  $f(x)$  . The  essence of parallel computing lies in the decomposition of the computation of    $f(x)$   in  independent computation units  and exploit their independence to execute as many of them as possible in parallel (simultaneously) so that the resulting execution is time-efﬁcient. Hence, the aim of parallelism is to produce efﬁcient computations. This is a non-trivial activity which (among other issues) involves specialized programming languages, speciﬁc compilation-time program analysis, and appropriate run-time scheduling techniques.  

Distributed computing As we have seen, the  essence  of distributed computing is different. It is on the  coordination in the presence of “adversaries”  (globally called  environment ) such as asynchrony, failures, locality, mobility, heterogeneity, limited bandwidth, restricted energy, etc. From the local point of view of each computing entity, these adversaries create uncertainty generating nondeterminism, which (when possible) has to be solved by an appropriate algorithm.  

A synoptic view In a few words, parallel computing focuses on the decomposition of a problem in independent parts (to beneﬁt from the existence of many processors), while distributed computing focuses on the cooperation of pre-existing imposed entities (in a given environment). Parallel computing is an  extension  of sequential computing in the sense any problem that can be solved by a parallel algorithm can be solved – generally very in ef cie ntl y – by a sequential algorithm. Differently, as we will see in the rest of this book, there are many distributed computing problems (distributed tasks) that have neither a counterpart, nor a meaning, in parallel (or sequential) computing.  

# 1.6 Summary  

A ﬁrst aim of this chapter was to introduce basic deﬁnitions related to distributed computing, and associated notions such as timing models (synchrony/asynchrony) and failure models. A second aim was to introduce a few important notions associated with fault-tolerant distributed computing, such as an impossibility result, and a non-trivial problem (computation of a distributed function) in the presence of channels experiencing transient message losses.  

An important point of distributed computing lies in the fact that the computing entities and their inputs are distributed. This attribute, which is imposed on the algorithm designer, directs the processes to coordinate in one way or another, according to the problem they have to solve. It is fundamental to note that this feature makes distributed computing and parallel computing different. In parallel computing, the inputs are initially centralized, and it is up to the algorithm designer to make the inputs as independent as possible so that they can be processed “in parallel” to obtain efﬁcient executions. Whereas in many distributed computing problems, the inputs are inherently distributed (see  Fig. 1.5 ). It follows that the heart of distributed computing consists in mastering of the uncertainty created by the environment, which is deﬁned by the distribution of the computing entities, asynchrony, process failures, communication failures, mobility, non-determinism, etc. (everything that can affect the computation and is not under its control).  

# 1.7 Bibliographic Notes  

•  There are many books on message-passing distributed computing in the presence of failures (e.g., [43, 88, 250, 271, 366, 367]). Whereas [368] is an introductory book addressing basic distributed computing problems encountered in  failure-free  synchronous and asynchronous distributed systems (e.g., mutual exclusion, global state computation, termination and deadlock detection, logical clocks, scalar and vector time, distributed check pointing and distributed properties detection, graph algorithms, etc.). •  Both the notion of a sequential process and the notion of concurrent computing were introduced by E.W. Dijkstra in his seminal papers [129, 130]. •  A recent (practical) introduction to distributed systems can be found in [402]. An introduction to the notion of a system model, and its relevance, appeared in [389]. •  The representation of a distributed execution as a partial order on a set of events is due to L. Lamport [255]. •  The notion of a Byzantine failure was introduced in the early 1980s, in the context of synchronous systems [263, 342]. •  The common decision-making problem seems to have been ﬁrst introduced by E. A. Akkoyunlu, E. Ekanadham K., and R.V. Huber in [26]. It was addressed in the late 1970s by J. Gray in the context of databases [192]. The effect of message losses on the termination of distributed algorithms is addressed in [248]. •  A  choice coordination  problem, where the processes are anonymous and must collectively select one among    $k\,\geq\,2$   possible alternatives, was introduced by M. Rabin in [353]. As they are anonymous, all processes have the same code. Moreover, a given alternative  $A$   (possible choice) can have the name  $a l t_{i}$   at  $p_{i}$   and the name  $a l t_{j}\neq a l t_{i}$   at another process  $p_{j}$  . To break symmetry and cope with non-determinism, the proposed solution is a randomized algorithm. A simple and pleasant presentation of this algorithm can be found in [405]. •  The readers interested in impossibility results in distributed computing should consult the monograph [39]. •  The notions of safety and liveness were made explicit and formalized by L. Lamport in [254]. Liveness is also discussed in [28].  

•  The impossibility proof of the common decision-making problem is from [389], where the coordination problem introduced in Section 1.2.5 is also presented. The most famous impossibility result of distributed computing concerns the consensus problem in the context of asynchronous systems prone to (even) a single process crash [162]. This impossibility will be studied in Part IV of the book.

 •  The computation of a global function whose inputs are distributed is a basic problem of distributed computing. Its formalization (under the name  distributed task ) and its investigation in the presence of one process crash was addressed for the ﬁrst time in [65, 296]. Since then, this problem has received a lot of attention (see e.g., [217]).

 •  The notion of a  message adversary  was introduced in the context of synchronous systems by N. Santoro and P. Widmayer (in the late eighties) under the name “mobile fault” [385]. It has since received a lot of attention (see e.g., [376, 386, 387]).

 •  The TREE-AD message adversary is from [251]. This paper considers the problem in a more involved context where    $n$   is not known by the processes.

 •  The connection between message adversaries and dynamic synchronous systems (where “dynamic” refers to the motion of processes) is from [251]. An introduction of graphs (called timevarying graphs) able to capture dynamic networks is presented in [100]. This graph formalism is particularly well-suited to these types of network. A survey on dynamic network models is presented in [252]. Theoretical foundations of dynamic networks are represented in [44].

 •  In several places in this chapter (and also in the book) we used the terms “process    $p_{i}$   learns” or “process  $p_{i}$   knows that ...”. These notions have been formalized since the late eighties, as shown in [103, 208, 298]. The corresponding knowledge theory is pretty powerful for explaining and understanding distributed computing [152, 297].

 •  This book does not address robot-oriented distributed computing. Interested readers should consult [163, 164, 349].

 •  The interested reader will ﬁnd a synoptic view of distributed computing versus parallel comput  

ing in [371].  

# 1.8 Exercises and Problems  

1. Show that the common decision-making problem cannot be solved even if the system is synchronous (there is a bound on message transfer delays, and this bound is known by the processes: the system model is    $S M P_{n}[\emptyset]$   weakened by message losses).

 2. Prove that the two-process coordination problem stated in Section 1.2.5 is impossible to solve.

 3. Let us consider the following message adversary TREE ${\mathrm{.AD}}(x)$  , where    $x\geq1$   is an integer constant initially known by the processes. TREE ${\mathrm{.AD}}(x)$   is TREE-AD with an additional constraint limiting its power. Let us remember that    $G(r)$   denotes the communication graph on which the message adversary does not suppress messages during round  $r$  . TREE ${\mathrm{.AD}}(x)$   is such that, for any    $r$  ,  $G(r)\cap G(r+1)\cdot\cdot\cdot\cap G(r+x-1)$   contains the same spanning tree. This means that any sequence of  $x$   consecutive communication graphs deﬁned by the adversary contains the same spanning tree. It is easy to see that TREE-AD( 1 ) is TREE-AD. Moreover, TREE-AD  $(n-1)$   states that the same communication spanning tree (not known by the processes) exists during the whole computation (made up of    $(n-1)$   rounds). Does the replacement of the message adversary TREE-AD by the message adversary TREE $\mathrm{AD}(x)$   allow the design of a more efﬁcient algorithm? Solution in [251].  

4. Is it possible to modify the algorithm in  Fig. 1.7  so that no process needs to know    $n$  ? Solution in [251].  